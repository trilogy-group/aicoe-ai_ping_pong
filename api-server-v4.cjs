const express = require("express");
const cors = require("cors");
const path = require("path");
const Anthropic = require("@anthropic-ai/sdk");
require("dotenv").config();

const app = express();
// Respect PORT env var (e.g. Render sets it) with a sensible default
const port = process.env.PORT || 3002;

// Middleware
app.use(cors());
app.use(express.json({ limit: "50mb" }));
// Serve static assets generated by `npm run build`
app.use(express.static(path.join(__dirname, "dist")));

// Helper function to add citations to Gemini responses using grounding metadata
function addCitations(text, groundingMetadata) {
  if (
    !groundingMetadata?.groundingSupports ||
    !groundingMetadata?.groundingChunks
  ) {
    return text;
  }

  const supports = groundingMetadata.groundingSupports;
  const chunks = groundingMetadata.groundingChunks;

  // Sort supports by end_index in descending order to avoid shifting issues when inserting
  const sortedSupports = [...supports].sort(
    (a, b) => (b.segment?.endIndex ?? 0) - (a.segment?.endIndex ?? 0)
  );

  let citedText = text;

  for (const support of sortedSupports) {
    const endIndex = support.segment?.endIndex;
    if (endIndex === undefined || !support.groundingChunkIndices?.length) {
      continue;
    }

    const citationLinks = support.groundingChunkIndices
      .map((i) => {
        const chunk = chunks[i];
        if (chunk?.web?.uri && chunk?.web?.title) {
          return `[${i + 1}: ${chunk.web.title}](${chunk.web.uri})`;
        }
        return null;
      })
      .filter(Boolean);

    if (citationLinks.length > 0) {
      const citationString = ` ${citationLinks.join(", ")}`;
      citedText =
        citedText.slice(0, endIndex) +
        citationString +
        citedText.slice(endIndex);
    }
  }

  // Add search queries used for transparency
  if (groundingMetadata.webSearchQueries?.length > 0) {
    citedText += `\n\n**Search queries used:** ${groundingMetadata.webSearchQueries.join(
      ", "
    )}`;
  }

  return citedText;
}

// Model driver implementations with search capabilities
const modelHandlers = {
  async gpt(prompt, context, useSearch = false) {
    try {
      if (!process.env.OPENAI_API_KEY) {
        throw new Error("OpenAI API key not configured");
      }

      const OpenAI = require("openai");
      const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

      console.log(
        `ü§ñ GPT request (${prompt.length} chars)${
          useSearch ? " with search" : ""
        }`
      );

      // Safely handle context and stepOutputs
      const safeContext = context || {};
      const safeStepOutputs = Array.isArray(safeContext.stepOutputs)
        ? safeContext.stepOutputs
        : [];
      const userInput = safeContext.userInput || "";

      const messages = [
        {
          role: "system",
          content:
            "You are a helpful AI assistant focused on providing practical, actionable responses with accurate, up-to-date information. When conducting research, always include proper source citations in format [Source: Publication Name, Article Title, Date, URL]. Stay focused on the user's specific request and avoid generic business language. Be engaging and creative while remaining helpful and direct.",
        },
        { role: "user", content: userInput },
      ];

      // Add step outputs as context (last 2 to avoid token limits)
      if (safeStepOutputs.length > 0) {
        const recentOutputs = safeStepOutputs.slice(-2);
        for (const output of recentOutputs) {
          if (output && typeof output === "string" && output.trim()) {
            messages.push({ role: "user", content: output });
          }
        }
      }

      // Add the current prompt
      messages.push({ role: "user", content: prompt });

      const requestConfig = {
        model: "gpt-4.1",
        tools: [{ type: "web_search_preview" }],
        input:
          prompt +
          "\nBased on the following context:\n" +
          messages.map((m) => `${m.role}: ${m.content}`).join("\n"),
      };

      const res = await openai.responses.create(requestConfig);

      const content = res.output[res.output.length - 1].content;
      const text = content.text || res.output_text;
      const citations =
        content.annotations?.map(
          (a) =>
            `[${a.type}] ${a.title} - ${a.url} (${a.start_index} - ${a.end_index})`
        ) || [];

      return `${text}\n\n${citations?.join("\n")}`;
    } catch (error) {
      console.error("GPT API error:", error);
      return "GPT API error: " + error.message;
    }
  },

  async claude(prompt, context, useSearch = false) {
    try {
      if (!process.env.ANTHROPIC_API_KEY) {
        throw new Error("Anthropic API key not configured");
      }

      const anthropic = new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY,
      });

      console.log(
        `üß† Claude request (${prompt.length} chars)${
          useSearch ? " with search and thinking" : ""
        }`
      );

      // Determine system prompt
      const isFinalArticleStep =
        prompt.includes("ultimate-final-article") ||
        prompt.includes(
          "DELIVER ONLY the complete, final, publication-ready article content"
        ) ||
        prompt.includes("Begin the article immediately");

      const defaultSystemPrompt =
        "You are Claude, an AI assistant focused on logical analysis, accuracy, and clear reasoning. " +
        "When conducting research, always include proper source citations in format [Source: Publication Name, Article Title, Date, URL]. " +
        "When tackling complex requests, think step by step and show your reasoning as analysis, followed by a clear answer.";

      const finalArticlePrompt =
        "You are Claude, a master content creator. For final article production: DO NOT provide thinking, analysis, or meta-commentary. " +
        "DELIVER ONLY the complete, final article content. Begin immediately with the article title and content.";

      const systemPrompt = isFinalArticleStep
        ? finalArticlePrompt
        : defaultSystemPrompt;

      // Safely handle context and stepOutputs with better error handling
      const safeContext = context || {};
      const safeStepOutputs = Array.isArray(safeContext.stepOutputs)
        ? safeContext.stepOutputs
        : [];
      const userInput = safeContext.userInput || "";

      // Build messages array with proper content
      const messages = [{ role: "user", content: userInput }];

      // Add step outputs as context (last 2 to avoid token limits)
      if (safeStepOutputs.length > 0) {
        const recentOutputs = safeStepOutputs.slice(-2);
        for (const output of recentOutputs) {
          if (output && typeof output === "string" && output.trim()) {
            messages.push({ role: "user", content: output });
          }
        }
      }

      // Add the current prompt
      messages.push({ role: "user", content: prompt });

      // Filter out empty messages
      const filteredMessages = messages.filter(
        (msg) => msg.content && msg.content.trim()
      );

      const requestConfig = {
        model: "claude-opus-4-20250514",
        max_tokens: 32000,
        system: systemPrompt,
        messages: filteredMessages,
        tools: [
          {
            name: "web_search",
            type: "web_search_20250305",
          },
        ],
        thinking: {
          type: "enabled",
          budget_tokens: 31999,
        },
      };

      // Send request as a streaming response
      const response = await anthropic.messages.create(requestConfig);

      console.log("üß† Claude response:", response);
      const msg = response.content
        .filter((c) => c.type === "text")
        .map((c) => c.text)
        .join("\n");

      return msg;
    } catch (error) {
      console.error("Claude API error:", error);
      return "Claude API error: " + error.message;
    }
  },

  async gemini(prompt, context, useSearch = false) {
    // -- Updated implementation using @google/genai official SDK with Google Search grounding --
    try {
      if (!process.env.GEMINI_API_KEY) {
        throw new Error("Gemini API key not configured");
      }

      console.log(
        `üíé Gemini request (${prompt.length} chars)${
          useSearch ? " with Google Search grounding" : ""
        }`
      );

      // Lazy-load the SDK to avoid cost if Gemini is disabled
      const { GoogleGenAI } = require("@google/genai");

      const ai = new GoogleGenAI({
        apiKey: process.env.GEMINI_API_KEY,
      });

      const modelName = "gemini-2.5-flash"; // Use Flash for better performance with grounding

      // Build config with Google Search grounding when needed
      const config = {
        temperature: 1.05,
        thinkingConfig: {
          thinkingBudget: -1,
        },
        responseMimeType: "text/plain",
      };

      // Add Google Search grounding tool if search is requested
      if (useSearch) {
        config.tools = [
          {
            googleSearch: {},
          },
        ];
        console.log("üîç Enabling Google Search grounding for Gemini");
      }

      // Combine context + prompt
      const combinedText = [
        context.userInput || "",
        ...context.stepOutputs.slice(-3),
        prompt,
      ]
        .filter(Boolean)
        .join("\n\n");

      const baseMessage = {
        role: "user",
        parts: [
          {
            text: combinedText,
          },
        ],
      };

      const requestParams = {
        model: modelName,
        config,
        contents: [baseMessage],
      };

      // --- Retry logic similar to previous implementation ---
      const { maxRetries, retryDelay, backoffMultiplier } =
        modelsConfig.retryPolicy;

      let attempt = 0;
      let delayMs = retryDelay;
      const sleep = (ms) => new Promise((res) => setTimeout(res, ms));

      let lastError;

      while (attempt <= maxRetries) {
        try {
          const stream = await ai.models.generateContentStream(requestParams);

          let fullText = "";
          let groundingMetadata = null;

          for await (const chunk of stream) {
            if (chunk.text) fullText += chunk.text;

            // Capture grounding metadata if available
            if (chunk.groundingMetadata) {
              groundingMetadata = chunk.groundingMetadata;
            }
          }

          if (!fullText.trim()) {
            throw new Error("No content returned from Gemini stream");
          }

          // If we have grounding metadata, add citations to the response
          if (useSearch && groundingMetadata) {
            const textWithCitations = addCitations(fullText, groundingMetadata);
            console.log(
              "‚úÖ Gemini response with Google Search grounding and citations"
            );
            return textWithCitations;
          }

          return fullText;
        } catch (err) {
          lastError = err;

          // Retry only on transient errors
          if (
            attempt < maxRetries &&
            ["ECONNRESET", "ETIMEDOUT"].includes(err.code) // network level
          ) {
            console.warn(
              `‚ö†Ô∏è Gemini attempt #${attempt + 1} failed: ${
                err.message
              }. Retrying in ${delayMs} ms‚Ä¶`
            );
            await sleep(delayMs);
            delayMs *= backoffMultiplier;
            attempt += 1;
            continue;
          }

          break; // non-retryable
        }
      }

      console.error("‚ùå Gemini failed:", lastError?.message || lastError);

      return "Gemini API error: " + (lastError?.message || "Unknown error");
    } catch (error) {
      console.error("Gemini API setup error:", error);
      return "Gemini API error: " + error.message;
    }
  },

  async grok(prompt, context, useSearch = false) {
    try {
      if (!process.env.GROK_API_KEY) {
        // Fallback to Gemini if available
        if (process.env.GEMINI_API_KEY) {
          console.log(
            "üîÑ Grok unavailable, falling back to Gemini with search"
          );
          return await modelHandlers.gemini(
            `Acting as Grok with real-time research capabilities: ${prompt}`,
            context,
            useSearch
          );
        }
        throw new Error(
          "Grok API key not configured and no fallback available"
        );
      }

      const axios = require("axios");
      console.log(
        `‚ö° Grok request (${prompt.length} chars)${
          useSearch ? " with deep search" : ""
        }`
      );

      const requestConfig = {
        model: "grok-3",
        system:
          "You are Grok, an AI with real-time information access and a witty personality. When conducting research, always include proper source citations in format [Source: Publication Name, Article Title, Date, URL]. Focus on STEM/math reasoning, live social-web research, and chain-of-thought analysis. Provide current, accurate information while staying focused on the user's specific request.",
        messages: [
          {
            role: "user",
            content: context.userInput,
          },
          ...context.stepOutputs
            .slice(-3)
            .map((c) => ({ role: "user", content: c })),
          {
            role: "user",
            content: prompt,
          },
          {
            role: "user",
            content: prompt,
          },
        ],
        temperature: 1,
        stream: false,
      };

      // Note: Grok may have native search without explicit tool configuration
      // The search capability is inherent to the model itself

      const response = await axios.post(
        "https://api.x.ai/v1/chat/completions",
        requestConfig,
        {
          headers: {
            Authorization: `Bearer ${process.env.GROK_API_KEY}`,
            "Content-Type": "application/json",
          },
        }
      );

      return response.data.choices[0].message.content;
    } catch (error) {
      console.error("Grok API error:", error);
      return "Grok API error: " + error.message;
    }
  },
};

// Workflow configuration
const modelsConfig = {
  stepOverrides: {
    article: {
      "clarify-brief": "gpt",
      "deep-research": "gemini",
      "first-draft": "gpt",
      "strengths-analysis": "grok",
      "initial-structure": "gpt",
      "logical-enhancement": "claude",
      "creative-polish": "gpt",
      "final-logic-check": "claude",
      "production-ready": "gpt",
    },
    email: {
      "decode-request": "gpt",
      "validate-response": "gemini",
      "craft-response": "gpt",
    },
    research: {
      "clarify-scope": "gpt",
      "broad-research": "gemini",
      "structure-findings": "gpt",
      "deep-dive-research": "gemini",
      "logical-analysis": "claude",
      "strategic-synthesis": "gpt",
      "final-report": "claude",
    },
  },
  fallbacks: {
    grok: "gemini",
    gemini: "gpt",
    claude: "gpt",
    gpt: null,
  },
  enabledDrivers: {
    gpt: true,
    claude: true,
    gemini: true,
    grok: true, // Now enabled by default since it's working
    "google-search": true, // Special validation step
    "all-models": true, // Special validation step
  },
  retryPolicy: {
    maxRetries: 3,
    retryDelay: 1000,
    backoffMultiplier: 2,
  },
  validationConfig: {
    googleSearchValidation: {
      maxParallelSearches: 5, // Max concurrent Google searches
      retryAttempts: 2, // Number of retries for each source validation
      invalidSourceThreshold: 0.1, // Percentage of invalid/questionable sources above which to warn
    },
  },
};

// Workflow Engine
class WorkflowEngine {
  resolveModel(stepModel, stepId, scenarioId) {
    // Check step-specific overrides first
    const stepOverrides = modelsConfig.stepOverrides[scenarioId];
    let targetModel = stepOverrides?.[stepId] || stepModel;

    // Handle special "all-models" validation step
    if (targetModel === "all-models") {
      return "all-models";
    }

    // Handle special "google-search" validation step
    if (targetModel === "google-search") {
      return "google-search";
    }

    // Apply fallback logic if the target model is disabled
    while (targetModel && !modelsConfig.enabledDrivers[targetModel]) {
      const fallback = modelsConfig.fallbacks[targetModel];
      if (fallback === null) {
        return null; // No more fallbacks available
      }
      targetModel = fallback;
      console.log(
        `üîÑ Model ${stepModel} disabled, falling back to ${targetModel}`
      );
    }

    return targetModel;
  }

  renderPrompt(template, context) {
    let rendered = template;

    // Replace {{userInput}} placeholder
    if (context.userInput) {
      rendered = rendered.replace(/\{\{userInput\}\}/g, context.userInput);
    }

    // Replace {{stepN}} placeholders with previous outputs
    if (Array.isArray(context.stepOutputs)) {
      context.stepOutputs.forEach((output, index) => {
        if (output && output.trim()) {
          const placeholder = `{{step${index + 1}}}`;
          rendered = rendered.replace(
            new RegExp(placeholder.replace(/[{}]/g, "\\$&"), "g"),
            output
          );
        }
      });
    }

    // Handle validation-specific placeholders
    if (context.validationResults) {
      rendered = rendered.replace(
        /\{\{gptValidation\}\}/g,
        context.validationResults.gpt || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{claudeValidation\}\}/g,
        context.validationResults.claude || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{geminiValidation\}\}/g,
        context.validationResults.gemini || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{grokValidation\}\}/g,
        context.validationResults.grok || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{originalContent\}\}/g,
        context.originalContent || "No content"
      );
    }

    // Replace {{content}} with the latest output for validation steps
    if (Array.isArray(context.stepOutputs) && context.stepOutputs.length > 0) {
      const latestOutput = context.stepOutputs[context.stepOutputs.length - 1];
      rendered = rendered.replace(/\{\{content\}\}/g, latestOutput || "");
    }

    return rendered;
  }

  // Determine if a step should use search capabilities
  shouldUseSearch(stepId, prompt) {
    // Steps that definitely need search
    const searchRequiredSteps = [
      "deep-research",
      "validate-response",
      "broad-research",
      "deep-dive-research",
      "multi-model-source-validation",
      "final-source-verification",
    ];

    // Keywords that indicate search should be used
    const searchKeywords = [
      "current",
      "latest",
      "recent",
      "up-to-date",
      "trending",
      "statistics",
      "data",
      "research",
      "sources",
      "verify",
      "validate",
      "fact-check",
      "confirm",
      "investigate",
      "WITH SOURCES",
      "CRITICAL:",
      "citations",
      "references",
    ];

    // Check if step requires search
    if (searchRequiredSteps.includes(stepId)) {
      return true;
    }

    // Check if prompt contains search-indicating keywords
    const lowerPrompt = prompt.toLowerCase();
    return searchKeywords.some((keyword) =>
      lowerPrompt.includes(keyword.toLowerCase())
    );
  }

  async executeMultiModelValidation(prompt, context) {
    console.log(`üîç Starting multi-model source validation with search`);

    const validationConfig = {
      gpt: "As GPT with web search capabilities, perform rigorous fact-checking on the sources and claims in the following content. Use search to verify facts and cross-check sources. Focus on logical consistency, factual accuracy, and identifying any potential misinformation. Include source citations for your verification:\n\n{{content}}",
      claude:
        "As Claude with thinking and web search, analyze the following content for source reliability and logical reasoning. Use search to verify claims and sources. Identify any potential hallucinations, unsupported claims, or questionable sources. Provide detailed reasoning for each assessment with citations:\n\n{{content}}",
      gemini:
        "As Gemini with Google grounding search, verify the sources and factual claims in the following content. Use grounding search to cross-reference with current information and identify any inconsistencies or unreliable sources. Include source citations:\n\n{{content}}",
      grok: "As Grok with real-time web access and deep search, validate the sources and current information in the following content. Use your native search capabilities to check for accuracy, recency, and reliability of claims, especially those related to recent events or data. Include source citations:\n\n{{content}}",
    };

    const models = ["gpt", "claude", "gemini", "grok"];
    const validationResults = {};

    // Run validation in parallel across all enabled models WITH SEARCH
    const validationPromises = models
      .filter((model) => modelsConfig.enabledDrivers[model])
      .map(async (model) => {
        try {
          console.log(
            `üîç Running ${model.toUpperCase()} validation with search`
          );
          const validationPrompt = this.renderPrompt(
            validationConfig[model],
            context
          );
          // Use search for all validation models
          const result = await modelHandlers[model](
            validationPrompt,
            context,
            true
          );

          validationResults[model] = result;
          console.log(
            `‚úÖ ${model.toUpperCase()} validation complete with search (${
              result.length
            } chars)`
          );
        } catch (error) {
          console.error(
            `‚ùå ${model.toUpperCase()} validation failed:`,
            error.message
          );
          validationResults[model] = `Validation failed: ${error.message}`;
        }
      });

    await Promise.all(validationPromises);

    // Store validation results in context for next step
    context.validationResults = validationResults;
    context.originalContent =
      context.stepOutputs[context.stepOutputs.length - 1];

    // Return validation summary
    const summaryText =
      `Multi-model source validation with search completed:\n\n` +
      Object.entries(validationResults)
        .map(
          ([model, result]) =>
            `${model.toUpperCase()} Assessment with Search (${
              result.length
            } chars):\n${result.substring(0, 200)}...`
        )
        .join("\n\n");

    return summaryText;
  }

  // NEW: Extract sources from content using comprehensive patterns
  extractSourcesFromContent(content) {
    // Handle undefined or null content
    if (!content || typeof content !== "string") {
      console.log(`‚ö†Ô∏è No valid content provided for source extraction`);
      return [];
    }

    const sources = new Set();

    // Pattern 1: URLs (http/https)
    const urlPattern = /https?:\/\/[^\s\)\]\}\<\>\n]+/g;
    const urls = content.match(urlPattern) || [];
    urls.forEach((url) => sources.add(url.replace(/[.,;:!?]*$/, ""))); // Remove trailing punctuation

    // Pattern 2: [Source: ...] format
    const sourcePattern1 = /\[Source:\s*([^\]]+)\]/gi;
    const sourceMatches1 = content.matchAll(sourcePattern1);
    for (const match of sourceMatches1) {
      sources.add(match[1].trim());
    }

    // Pattern 3: (Source: ...) format
    const sourcePattern2 = /\(Source:\s*([^\)]+)\)/gi;
    const sourceMatches2 = content.matchAll(sourcePattern2);
    for (const match of sourceMatches2) {
      sources.add(match[1].trim());
    }

    // Pattern 4: According to [source]
    const accordingPattern = /According to\s+([^,.\n]+)/gi;
    const accordingMatches = content.matchAll(accordingPattern);
    for (const match of accordingMatches) {
      sources.add(match[1].trim());
    }

    // Pattern 5: As reported by [source]
    const reportedPattern = /As reported by\s+([^,.\n]+)/gi;
    const reportedMatches = content.matchAll(reportedPattern);
    for (const match of reportedMatches) {
      sources.add(match[1].trim());
    }

    // Pattern 6: [Author/Publication] states/reports/claims
    const authorPattern =
      /([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+(?:states|reports|claims|found|discovered|published)/g;
    const authorMatches = content.matchAll(authorPattern);
    for (const match of authorMatches) {
      if (match[1].length > 3 && match[1].length < 50) {
        // Reasonable length check
        sources.add(match[1].trim());
      }
    }

    // Pattern 7: Study/Research/Report references
    const studyPattern =
      /(?:study|research|report|paper|article)\s+(?:by|from|published by)\s+([^,.\n]+)/gi;
    const studyMatches = content.matchAll(studyPattern);
    for (const match of studyMatches) {
      sources.add(match[1].trim());
    }

    console.log(`üîç Extracted ${sources.size} sources from content`);
    return Array.from(sources).filter((source) => source.length > 2); // Filter out very short matches
  }

  // NEW: Validate a single source using Google search
  async validateSingleSource(source, originalContent, retryAttempts = 2) {
    const config = modelsConfig.validationConfig.googleSearchValidation;

    for (let attempt = 0; attempt < retryAttempts; attempt++) {
      try {
        console.log(
          `üîç Validating source: "${source}" (attempt ${attempt + 1})`
        );

        const searchQuery = `"${source}" site verification reliability`;
        const searchPrompt = `You are a fact-checker with Google search access. Validate the reliability and existence of this source: "${source}"
        
        Original context: ${originalContent.substring(0, 500)}...
        
        Use Google search to:
        1. Verify if this source exists and is legitimate
        2. Check the credibility and reliability of the source
        3. Determine if the source actually contains the information claimed
        4. Identify any red flags or signs of unreliability
        
        Search query: ${searchQuery}
        
        Provide your assessment in this format:
        STATUS: [VALID/INVALID/QUESTIONABLE]
        CONFIDENCE: [1-10]
        REASON: [Brief explanation]
        EVIDENCE: [What you found through search]
        RECOMMENDATION: [Keep/Remove/Verify]`;

        // Use web search to validate the source
        const result = await this.searchWeb(searchQuery);

        // Use Claude to analyze the search results
        const analysisPrompt = `${searchPrompt}
        
        Search Results:
        ${result}
        
        Based on these search results, provide your validation assessment.`;

        const analysis = await modelHandlers.claude(analysisPrompt, {}, false);

        // Parse the analysis
        const statusMatch = analysis.match(
          /STATUS:\s*(VALID|INVALID|QUESTIONABLE)/i
        );
        const confidenceMatch = analysis.match(/CONFIDENCE:\s*(\d+)/);
        const reasonMatch = analysis.match(/REASON:\s*([^\n]+)/);
        const recommendationMatch = analysis.match(
          /RECOMMENDATION:\s*(Keep|Remove|Verify)/i
        );

        return {
          source,
          status: statusMatch ? statusMatch[1].toUpperCase() : "QUESTIONABLE",
          confidence: confidenceMatch ? parseInt(confidenceMatch[1]) : 5,
          reason: reasonMatch ? reasonMatch[1].trim() : "Unable to determine",
          evidence: result.substring(0, 300),
          recommendation: recommendationMatch
            ? recommendationMatch[1].toUpperCase()
            : "VERIFY",
          searchQuery,
          analysis: analysis,
        };
      } catch (error) {
        console.error(`‚ùå Error validating source "${source}":`, error.message);
        if (attempt === retryAttempts - 1) {
          return {
            source,
            status: "ERROR",
            confidence: 0,
            reason: `Validation failed: ${error.message}`,
            evidence: "",
            recommendation: "VERIFY",
            searchQuery: "",
            analysis: "",
          };
        }
        // Wait before retry
        await new Promise((resolve) => setTimeout(resolve, 1000));
      }
    }
  }

  // NEW: Execute Google search validation for all sources
  async executeGoogleSearchValidation(prompt, context) {
    console.log(`üåê Starting Google search validation for all sources`);

    const config = modelsConfig.validationConfig.googleSearchValidation;
    const currentContent = context.stepOutputs[context.stepOutputs.length - 1];

    // Extract all sources from the content
    const sources = this.extractSourcesFromContent(currentContent);

    if (sources.length === 0) {
      console.log(`‚ÑπÔ∏è No sources found in content for validation`);

      // Clean content by removing all reference patterns
      const cleanedContent = this.removeAllReferences(currentContent);

      // Store empty results in context for final verification
      context.googleSearchValidation = {
        totalSources: 0,
        validationResults: [],
        validSources: [],
        invalidSources: [],
        questionableSources: [],
        errorSources: [],
        invalidPercentage: 0,
        flaggedSources: [],
        cleanedContent: cleanedContent,
        timestamp: new Date().toISOString(),
      };

      return `Google Search Validation Report:

üìä SUMMARY:
- Total sources found: 0
- No sources to validate
- Content cleaned of reference patterns

‚úÖ CLEANED CONTENT:
The content has been cleaned to remove any reference patterns and citation language. Here's the fact-based version:

${cleanedContent}

‚úÖ All reference language has been removed. Content now presents facts without citation claims.`;
    }

    console.log(
      `üîç Found ${sources.length} sources to validate via Google search`
    );

    // Limit the number of parallel searches to avoid overwhelming the API
    const maxParallel = Math.min(sources.length, config.maxParallelSearches);
    const sourceChunks = [];

    for (let i = 0; i < sources.length; i += maxParallel) {
      sourceChunks.push(sources.slice(i, i + maxParallel));
    }

    const validationResults = [];

    // Process sources in chunks to manage API rate limits
    for (const chunk of sourceChunks) {
      console.log(`üîç Processing chunk of ${chunk.length} sources`);

      const chunkPromises = chunk.map((source) =>
        this.validateSingleSource(source, currentContent, config.retryAttempts)
      );

      try {
        const chunkResults = await Promise.all(chunkPromises);
        validationResults.push(...chunkResults);

        // Brief pause between chunks
        if (sourceChunks.length > 1) {
          await new Promise((resolve) => setTimeout(resolve, 1000));
        }
      } catch (error) {
        console.error(`‚ùå Error processing source chunk:`, error.message);
      }
    }

    // Analyze results
    const validSources = validationResults.filter((r) => r.status === "VALID");
    const invalidSources = validationResults.filter(
      (r) => r.status === "INVALID"
    );
    const questionableSources = validationResults.filter(
      (r) => r.status === "QUESTIONABLE"
    );
    const errorSources = validationResults.filter((r) => r.status === "ERROR");

    const invalidPercentage =
      (invalidSources.length + questionableSources.length) /
      validationResults.length;

    console.log(`üìä Google search validation complete:
    - Valid: ${validSources.length}
    - Invalid: ${invalidSources.length}
    - Questionable: ${questionableSources.length}
    - Errors: ${errorSources.length}
    - Invalid percentage: ${Math.round(invalidPercentage * 100)}%`);

    // If no sources are valid or too many are invalid, clean the content
    let cleanedContent = currentContent;
    if (validSources.length === 0 || invalidPercentage > 0.5) {
      console.log(`üßπ Cleaning content due to insufficient valid sources`);
      cleanedContent = this.removeAllReferences(currentContent);
    }

    // Store results in context for final verification
    context.googleSearchValidation = {
      totalSources: sources.length,
      validationResults,
      validSources,
      invalidSources,
      questionableSources,
      errorSources,
      invalidPercentage,
      flaggedSources: [...invalidSources, ...questionableSources],
      cleanedContent: cleanedContent,
      timestamp: new Date().toISOString(),
    };

    // Generate summary report
    const summaryText = `Google Search Validation Report:
    
üìä SUMMARY:
- Total sources checked: ${sources.length}
- Valid sources: ${validSources.length}
- Invalid sources: ${invalidSources.length}
- Questionable sources: ${questionableSources.length}
- Validation errors: ${errorSources.length}
- Invalid percentage: ${Math.round(invalidPercentage * 100)}%

${
  validSources.length === 0 || invalidPercentage > 0.5
    ? `üßπ CONTENT CLEANED:
Since no sources could be validated or too many sources were invalid, all references have been removed. Here's the cleaned content:

${cleanedContent}

‚úÖ Content now presents facts without citation claims.`
    : `üö® FLAGGED SOURCES:
${[...invalidSources, ...questionableSources]
  .map((s) => `- "${s.source}" (${s.status}): ${s.reason}`)
  .join("\n")}

‚úÖ VERIFIED SOURCES:
${validSources
  .map((s) => `- "${s.source}" (Confidence: ${s.confidence}/10)`)
  .join("\n")}`
}

${
  invalidPercentage > config.invalidSourceThreshold
    ? `‚ö†Ô∏è WARNING: ${Math.round(
        invalidPercentage * 100
      )}% of sources are invalid/questionable (threshold: ${Math.round(
        config.invalidSourceThreshold * 100
      )}%)`
    : "‚úÖ Source reliability within acceptable thresholds"
}`;

    return summaryText;
  }

  // NEW: Web search helper method
  async searchWeb(query) {
    console.log(`üîç Searching web for: "${query}"`);

    try {
      // Use the most appropriate search-enabled model
      // Priority: Grok (native real-time) > Gemini (Google search) > Claude (web search)
      let searchModel = "grok";
      if (!modelsConfig.enabledDrivers.grok) {
        searchModel = modelsConfig.enabledDrivers.gemini ? "gemini" : "claude";
      }

      const searchPrompt = `Perform a web search for: "${query}"
      
      Please search for information about this query and provide:
      1. Key findings from the search results
      2. Relevant sources and URLs
      3. Credibility assessment of the sources found
      4. Any red flags or concerns about the information
      
      Focus on factual, verifiable information and note the reliability of sources.`;

      // Use the search-enabled model with search capability
      const result = await modelHandlers[searchModel](
        searchPrompt,
        {
          userInput: query,
          stepOutputs: [],
        },
        true
      ); // Enable search

      console.log(`‚úÖ Web search completed using ${searchModel.toUpperCase()}`);
      return result;
    } catch (error) {
      console.error(`‚ùå Web search failed:`, error.message);

      // Fallback to a basic search result if all else fails
      return `Search for "${query}" encountered an error: ${error.message}
      
      Unable to perform web search at this time. Source validation will be limited to cross-referencing with existing knowledge.`;
    }
  }

  async executeStep(step, context, scenarioId) {
    // Validate step object
    if (!step || typeof step !== "object") {
      throw new Error("Invalid step object provided");
    }

    if (!step.id) {
      throw new Error("Step object missing required 'id' property");
    }

    if (!step.model) {
      throw new Error("Step object missing required 'model' property");
    }

    // ENHANCED: Check if this is an enhanced workflow step with capabilities
    if (step.capabilities && Array.isArray(step.capabilities)) {
      return await this.executeEnhancedStep(step, context, scenarioId);
    }

    // Legacy workflow execution path
    const targetModel = this.resolveModel(step.model, step.id, scenarioId);

    if (!targetModel) {
      throw new Error("No available model for this step");
    }

    // Handle special multi-model validation step
    if (targetModel === "all-models") {
      return await this.executeMultiModelValidation(
        step.rawPrompt || step.prompt,
        context
      );
    }

    // NEW: Handle Google search validation step
    if (targetModel === "google-search") {
      return await this.executeGoogleSearchValidation(
        step.rawPrompt || step.prompt,
        context
      );
    }

    // Handle final verification step with validation context
    if (
      step.id === "final-source-verification" &&
      (context.validationResults || context.googleSearchValidation)
    ) {
      // Safely access validation results with fallbacks
      const googleValidation = context.googleSearchValidation || {};
      const validSources = googleValidation.validSources || [];
      const invalidSources = googleValidation.invalidSources || [];
      const questionableSources = googleValidation.questionableSources || [];
      const totalSources = googleValidation.totalSources || 0;
      const invalidPercentage = googleValidation.invalidPercentage || 0;
      const cleanedContent = googleValidation.cleanedContent;

      // Safely get the current content
      const currentContent =
        Array.isArray(context.stepOutputs) && context.stepOutputs.length > 0
          ? context.stepOutputs[context.stepOutputs.length - 1]
          : "";

      // If no sources were validated or too many are invalid, return cleaned content
      if (
        validSources.length === 0 ||
        invalidPercentage > 0.5 ||
        totalSources === 0
      ) {
        const finalCleanedContent =
          cleanedContent || this.removeAllReferences(currentContent);

        return `Final Source Verification Complete:

üìä VERIFICATION SUMMARY:
- Total sources found: ${totalSources}
- Valid sources: ${validSources.length}
- Invalid/Questionable sources: ${
          invalidSources.length + questionableSources.length
        }
- Action taken: All references removed

‚úÖ FINAL CLEANED CONTENT:
${finalCleanedContent}

üîç VERIFICATION NOTES:
Since no sources could be validated or the majority were unreliable, all reference language has been removed. The content now presents facts without citation claims, ensuring accuracy and reliability.`;
      }

      const verificationPrompt = `You are Claude with thinking and web search capabilities. You have received source validation assessments from all 4 AI models (GPT, Claude, Gemini, and Grok)${
        context.googleSearchValidation
          ? " and Google Search validation results"
          : ""
      }. Your task is to:

1. Use web search to independently verify any questionable sources identified
2. Analyze all validation reports with special trust for Grok and Gemini's source assessments
3. ${
        context.googleSearchValidation
          ? "Review Google Search validation results for definitive source verification"
          : "Focus on multi-model validation results"
      }
4. Identify any hallucinated or unreliable sources that need removal
5. Provide a final cleaned version of the content with problematic sources removed
6. List what changes were made and why, with ${
        context.googleSearchValidation ? "search-verified" : "multi-model"
      } reasoning

Validation Reports:
GPT Assessment: {{gptValidation}}
Claude Assessment: {{claudeValidation}}
Gemini Assessment: {{geminiValidation}}
Grok Assessment: {{grokValidation}}${
        context.googleSearchValidation
          ? `
Google Search Validation Results: 
- Total sources checked: ${totalSources}
- Valid sources: ${validSources.length}
- Invalid sources: ${invalidSources.length}
- Questionable sources: ${questionableSources.length}
- Flagged sources for removal: ${[...invalidSources, ...questionableSources]
              .map((s) => `"${s.source}" (${s.status}: ${s.reason})`)
              .join(", ")}
- Invalid percentage: ${Math.round(invalidPercentage * 100)}%`
          : ""
      }

Original Content:
{{originalContent}}

${
  context.googleSearchValidation
    ? "Based on the Google Search validation results, remove or modify all content related to the flagged sources. Pay special attention to sources marked as INVALID or QUESTIONABLE."
    : "Use your search capabilities to verify any disputed sources and provide your final verified content with change summary."
}`;

      const renderedPrompt = this.renderPrompt(verificationPrompt, context);
      console.log(
        `üöÄ Workflow Engine: Final source verification with Claude + ${
          context.googleSearchValidation
            ? "Google search results"
            : "multi-model validation"
        }`
      );

      return await modelHandlers.claude(renderedPrompt, context, true);
    }

    const renderedPrompt = this.renderPrompt(
      step.rawPrompt || step.prompt,
      context
    );

    // Determine if this step should use search
    const useSearch = this.shouldUseSearch(step.id, renderedPrompt);

    console.log(
      `üöÄ Workflow Engine: Executing step "${
        step.id
      }" with ${targetModel.toUpperCase()}${useSearch ? " + search" : ""}`
    );

    return await modelHandlers[targetModel](renderedPrompt, context, useSearch);
  }

  // NEW: Enhanced workflow step execution with capability-based routing
  async executeEnhancedStep(step, context, scenarioId) {
    console.log(
      `üéØ Enhanced Workflow: Processing step "${
        step.id
      }" with capabilities: [${step.capabilities.join(", ")}]`
    );

    // Capability-based model selection
    const targetModel = this.selectOptimalModel(
      step.capabilities,
      step.prioritizeBy
    );

    if (!targetModel) {
      throw new Error(
        `No model available for capabilities: ${step.capabilities.join(", ")}`
      );
    }

    const routingReason = `Selected for capabilities: ${step.capabilities.join(
      "+"
    )} (optimized for ${step.prioritizeBy || "accuracy"})`;
    console.log(
      `üéØ Capability routing: ${step.capabilities.join(
        "+"
      )} ‚Üí ${targetModel.toUpperCase()} (${routingReason})`
    );

    const renderedPrompt = this.renderPrompt(
      step.rawPrompt || step.prompt,
      context
    );

    // Enhanced steps that need search capabilities
    const useSearch =
      this.shouldUseSearch(step.id, renderedPrompt) ||
      step.capabilities.includes("live-web") ||
      step.capabilities.includes("real-time-data") ||
      step.capabilities.includes("fact-checking");

    console.log(
      `üöÄ Enhanced Workflow Engine: Executing step "${
        step.id
      }" with ${targetModel.toUpperCase()}${useSearch ? " + search" : ""}`
    );

    const result = await modelHandlers[targetModel](
      renderedPrompt,
      context,
      useSearch
    );

    // Enhanced validation if requested
    if (step.requiresValidation && step.validationType) {
      console.log(`üîç Running enhanced ${step.validationType} validation`);
      return await this.runEnhancedValidation(
        result,
        step.validationType,
        context
      );
    }

    return result;
  }

  // NEW: Capability-based model selection (simplified version for API server)
  selectOptimalModel(capabilities, prioritizeBy = "accuracy") {
    // Model capability mappings (updated to match enhanced workflow capabilities)
    const modelCapabilities = {
      gpt: [
        "creative-polish",
        "json-output",
        "human-like-voice",
        "creative_polish",
        "json_output",
        "fact_checking",
        "structural-analysis",
      ],
      claude: [
        "long-form-narrative",
        "structural-analysis",
        "logical-reasoning",
        "comprehensive-review",
        "logic-audit",
        "fact-checking",
        "source_verification",
        "logic_audit",
        "long_form_narrative",
      ],
      gemini: [
        "high-context-analysis",
        "document-analysis",
        "comprehensive-review",
        "fact-checking",
        "source-verification",
        "high_volume_research",
        "multimodal_rag",
        "document_analysis",
        "long_context",
      ],
      grok: [
        "live-web",
        "real-time-data",
        "fact-checking",
        "high-volume-research",
        "stem_math_reasoning",
        "real_time_data",
        "live_web",
        "source_validation",
      ],
    };

    // Find models that can handle ALL required capabilities
    const availableModels = Object.keys(modelCapabilities).filter(
      (model) =>
        modelsConfig.enabledDrivers[model] &&
        capabilities.every((cap) => modelCapabilities[model].includes(cap))
    );

    if (availableModels.length === 0) {
      // Fallback: find model with most matching capabilities
      const candidateModels = Object.keys(modelCapabilities)
        .filter((model) => modelsConfig.enabledDrivers[model])
        .map((model) => ({
          model,
          matchScore: capabilities.filter((cap) =>
            modelCapabilities[model].includes(cap)
          ).length,
        }))
        .sort((a, b) => b.matchScore - a.matchScore);

      if (candidateModels.length > 0) {
        console.log(
          `‚ö†Ô∏è No perfect match for [${capabilities.join(
            ", "
          )}], using best available: ${candidateModels[0].model.toUpperCase()}`
        );
        return candidateModels[0].model;
      }
      return null;
    }

    // Priority-based selection among capable models
    if (prioritizeBy === "context" && availableModels.includes("gemini")) {
      return "gemini"; // 1M context window
    }
    if (prioritizeBy === "accuracy" && availableModels.includes("claude")) {
      return "claude"; // Highest accuracy score
    }
    if (prioritizeBy === "cost" && availableModels.includes("gemini")) {
      return "gemini"; // Lowest cost tier
    }
    if (prioritizeBy === "latency" && availableModels.includes("gpt")) {
      return "gpt"; // Fastest response
    }

    // Default to first available model
    return availableModels[0];
  }

  // NEW: Enhanced validation using cross-model checking
  async runEnhancedValidation(content, validationType, context) {
    console.log(`üîç Running enhanced ${validationType} validation`);

    const validationPrompts = {
      fact_check: `You are a fact-checking expert. Analyze the following content for factual accuracy and logical consistency. Identify any questionable claims, unsupported statements, or potential misinformation. Rate your confidence in the content's accuracy (1-10):\n\n${content}`,
      source_verify: `You are a source verification specialist. Examine the following content for source reliability, citation quality, and reference authenticity. Identify any questionable sources or unsupported claims. Rate source reliability (1-10):\n\n${content}`,
      logic_audit: `You are a logic and reasoning expert. Analyze the following content for logical consistency, argument structure, and reasoning quality. Identify any logical fallacies, inconsistencies, or weak arguments. Rate logical coherence (1-10):\n\n${content}`,
    };

    // Use two different models for cross-validation
    const validationModels =
      validationType === "fact_check"
        ? ["gpt", "claude"]
        : validationType === "source_verify"
        ? ["grok", "gemini"]
        : ["claude", "gpt"]; // logic_audit

    const prompt = validationPrompts[validationType];

    try {
      const validationPromises = validationModels
        .filter((model) => modelsConfig.enabledDrivers[model])
        .slice(0, 2) // Limit to 2 models for performance
        .map(async (model) => {
          try {
            return await modelHandlers[model](prompt, context, true); // Use search for validation
          } catch (error) {
            return `Validation failed: ${error.message}`;
          }
        });

      const validationResults = await Promise.all(validationPromises);

      // Return original content with validation summary
      return `${content}\n\n---\nüîç Enhanced ${validationType} validation completed:\n${validationResults
        .map(
          (result, i) =>
            `${validationModels[i].toUpperCase()}: ${result.substring(
              0,
              200
            )}...`
        )
        .join("\n\n")}`;
    } catch (error) {
      console.error(`‚ùå Enhanced validation failed:`, error.message);
      return content; // Return original content if validation fails
    }
  }

  toggleDriver(driverName, enabled) {
    modelsConfig.enabledDrivers[driverName] = enabled;
    console.log(`üîß Driver ${driverName} ${enabled ? "enabled" : "disabled"}`);
  }

  getDriverStatus() {
    return { ...modelsConfig.enabledDrivers };
  }

  // NEW: Helper to remove all reference patterns from content
  removeAllReferences(content) {
    if (!content || typeof content !== "string") {
      return content;
    }

    let cleanedContent = content;

    // Remove [Source: ...] but keep any preceding substantive content
    cleanedContent = cleanedContent.replace(/\s*\[Source:\s*([^\]]+)\]/gi, "");

    // Remove (Source: ...) but keep any preceding substantive content
    cleanedContent = cleanedContent.replace(/\s*\(Source:\s*([^\)]+)\)/gi, "");

    // Remove standalone URLs but preserve content around them
    cleanedContent = cleanedContent.replace(
      /\s*https?:\/\/[^\s\)\]\}\<\>\n]+\s*/g,
      " "
    );

    // Remove citation patterns like "(Author, Year)" or "[1]" or "[Author 2023]"
    cleanedContent = cleanedContent.replace(
      /\s*\([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*,?\s*\d{4}\)\s*/g,
      " "
    );
    cleanedContent = cleanedContent.replace(
      /\s*\[[^\]]*\d{4}[^\]]*\]\s*/g,
      " "
    );
    cleanedContent = cleanedContent.replace(/\s*\[\d+\]\s*/g, " ");

    // PRESERVE substantive content - only remove introductory citation phrases, not the facts
    // Instead of removing entire sentences, just remove the attribution parts
    cleanedContent = cleanedContent.replace(
      /According to\s+[^,.\n]+[,.]?\s*/gi,
      ""
    );
    cleanedContent = cleanedContent.replace(
      /As reported by\s+[^,.\n]+[,.]?\s*/gi,
      ""
    );
    cleanedContent = cleanedContent.replace(
      /The\s+(?:study|research|report|paper|article)\s+by\s+[^,.\n]+[,.]?\s*/gi,
      "The research "
    );

    // Remove author attributions but keep the actual findings/claims
    cleanedContent = cleanedContent.replace(
      /([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+(?:states|reports|claims|found|discovered|published)\s+(?:that\s+)?/gi,
      "Research shows "
    );

    // Replace research introduction phrases with neutral versions
    cleanedContent = cleanedContent.replace(
      /(?:research shows|studies indicate|data suggests|evidence suggests|findings reveal|analysis shows)\s+that\s+/gi,
      ""
    );
    cleanedContent = cleanedContent.replace(
      /(?:researchers?|scientists?|experts?|analysts?)\s+(?:found|discovered|determined|concluded|reported|stated)\s+(?:that\s+)?/gi,
      ""
    );

    // Clean up punctuation and spacing issues
    cleanedContent = cleanedContent.replace(/\s*,\s*,/g, ","); // Remove double commas
    cleanedContent = cleanedContent.replace(/\s*\.\s*\./g, "."); // Remove double periods
    cleanedContent = cleanedContent.replace(/\s+/g, " "); // Normalize whitespace
    cleanedContent = cleanedContent.replace(/\s*,\s*\./g, "."); // Remove comma before period
    cleanedContent = cleanedContent.replace(/\.\s*,/g, "."); // Remove comma after period
    cleanedContent = cleanedContent.replace(/\s*\.\s*/g, ". "); // Normalize period spacing
    cleanedContent = cleanedContent.replace(/\s*,\s*/g, ", "); // Normalize comma spacing

    // Remove leftover fragments but preserve meaningful sentences
    cleanedContent = cleanedContent.replace(
      /\s*,\s*the\s+data\s+shows\s*/gi,
      " "
    );
    cleanedContent = cleanedContent.replace(
      /\s*,\s*the\s+(?:study|research)\s+(?:shows|indicates)\s*/gi,
      " "
    );

    // Fix sentence beginnings that might have been broken
    cleanedContent = cleanedContent.replace(/\.\s*The\s*\./g, ".");
    cleanedContent = cleanedContent.replace(/\.\s*Research\s+\./g, ".");

    // Ensure sentences start with capital letters after cleanup
    cleanedContent = cleanedContent.replace(
      /\.\s+([a-z])/g,
      (match, letter) => ". " + letter.toUpperCase()
    );

    // Final cleanup
    cleanedContent = cleanedContent.replace(/\s+/g, " ").trim();
    cleanedContent = cleanedContent.replace(/\s*\.\s*$/g, "."); // Ensure proper ending

    return cleanedContent;
  }
}

const workflowEngine = new WorkflowEngine();

// API Routes
app.get("/api/test", (req, res) => {
  res.status(200).send("Test route is working!");
});

app.post("/api/generate", async (req, res) => {
  const { model, prompt, context, useSearch } = req.body;

  if (!model || !prompt) {
    return res.status(400).json({ error: "Model and prompt are required" });
  }

  const handler = modelHandlers[model];
  if (!handler) {
    return res.status(400).json({ error: "Unsupported model" });
  }

  try {
    const result = await handler(prompt, context, useSearch);
    res.json({ text: result });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Legacy streaming API deprecation
app.post("/api/stream", async (req, res) => {
  return res.status(410).json({
    success: false,
    error: "Streaming API deprecated. Use /api/run for regular responses.",
    migration:
      "Update client to use regular HTTP requests with /api/run endpoint",
  });
});

// Driver management
app.post("/api/drivers/toggle", (req, res) => {
  try {
    const { driver, enabled } = req.body;
    workflowEngine.toggleDriver(driver, enabled);

    res.json({
      success: true,
      drivers: workflowEngine.getDriverStatus(),
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message,
    });
  }
});

app.get("/api/drivers", (req, res) => {
  res.json({
    success: true,
    drivers: workflowEngine.getDriverStatus(),
    capabilities: {
      gpt: {
        strengths: [
          "logic_audit",
          "creative_polish",
          "fact_checking",
          "json_output",
        ],
        contextLimit: 128000,
        costTier: "medium",
      },
      claude: {
        strengths: [
          "long_form_narrative",
          "structural_analysis",
          "logical_reasoning",
        ],
        contextLimit: 200000,
        costTier: "medium",
      },
      gemini: {
        strengths: [
          "high_volume_research",
          "multimodal_rag",
          "document_analysis",
        ],
        contextLimit: 1000000,
        costTier: "low",
      },
      grok: {
        strengths: [
          "stem_math_reasoning",
          "real_time_data",
          "social_web_search",
        ],
        contextLimit: 128000,
        costTier: "high",
      },
    },
  });
});

// Health check
app.get("/api/health", (req, res) => {
  res.json({
    status: "ok",
    timestamp: new Date().toISOString(),
    version: "4.0.0-standard",
    models: {
      gpt: !!process.env.OPENAI_API_KEY,
      claude: !!process.env.ANTHROPIC_API_KEY,
      gemini: !!process.env.GEMINI_API_KEY,
      grok: !!process.env.GROK_API_KEY,
    },
    drivers: workflowEngine.getDriverStatus(),
  });
});

// Any requests that don't match the API route should be handled by the frontend
app.use((req, res) => {
  res.sendFile(path.join(__dirname, "dist", "index.html"));
});

app.listen(port, () => {
  console.log(
    `üöÄ AI Ping-Pong Studio v4 API Server running on http://localhost:${port}`
  );
  console.log(
    `Main generation endpoint: http://localhost:${port}/api/generate`
  );
  console.log(`\nüîë API Key Status:`);
  console.log(
    `   OpenAI (GPT): ${
      process.env.OPENAI_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   Anthropic (Claude): ${
      process.env.ANTHROPIC_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   Google (Gemini): ${
      process.env.GEMINI_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   xAI (Grok): ${
      process.env.GROK_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );

  console.log(`\nüîß Driver Status:`);
  const drivers = workflowEngine.getDriverStatus();
  Object.entries(drivers).forEach(([name, enabled]) => {
    console.log(
      `   ${name.toUpperCase()}: ${enabled ? "‚úÖ Enabled" : "‚ùå Missing"}`
    );
  });

  if (
    !process.env.OPENAI_API_KEY &&
    !process.env.ANTHROPIC_API_KEY &&
    !process.env.GEMINI_API_KEY
  ) {
    console.log(`\n‚ùó WARNING: No API keys found!`);
    console.log(`   Add API keys to your .env file:`);
    console.log(`   OPENAI_API_KEY=your_openai_key`);
    console.log(`   ANTHROPIC_API_KEY=your_anthropic_key`);
    console.log(`   GEMINI_API_KEY=your_gemini_key`);
    console.log(`   GROK_API_KEY=your_grok_key`);
  }
  console.log(``);
});
