const express = require("express");
const cors = require("cors");
const path = require("path");
const Anthropic = require("@anthropic-ai/sdk");
const passport = require("passport");
const GoogleStrategy = require("passport-google-oauth20").Strategy;
const session = require("express-session");
require("dotenv").config();

const app = express();
// Respect PORT env var (e.g. Render sets it) with a sensible default
const port = process.env.PORT || 3002;

// Session configuration
app.use(
  session({
    secret: process.env.SESSION_SECRET || "your-secret-key-here",
    resave: false,
    saveUninitialized: false,
    name: 'ai-ping-pong-session',
    cookie: {
      secure: false, // Set to false for development (HTTP)
      httpOnly: true,
      maxAge: 24 * 60 * 60 * 1000, // 24 hours
      sameSite: 'lax', // Important for OAuth callbacks
    },
  })
);

// Middleware
app.use(cors({
  origin: process.env.NODE_ENV === "production" 
    ? ["https://your-domain.com"] 
    : ["http://localhost:3000", "http://localhost:3002", "http://127.0.0.1:3000"],
  credentials: true,
  optionsSuccessStatus: 200,
}));
app.use(express.json({ limit: "50mb" }));
app.use(passport.initialize());
app.use(passport.session());

// Serve static assets generated by `npm run build`
app.use(express.static(path.join(__dirname, "dist")));

// Google OAuth Strategy
passport.use(
  new GoogleStrategy(
    {
      clientID: process.env.GOOGLE_CLIENT_ID,
      clientSecret: process.env.GOOGLE_CLIENT_SECRET,
      callbackURL: "/auth/google/callback",
    },
    async (accessToken, refreshToken, profile, done) => {
      console.log('üîë Google OAuth strategy callback triggered');
      console.log('üë§ Google profile:', profile.displayName, profile.emails?.[0]?.value);
      
      // Here you would typically save the user to your database
      // For now, we'll just return the profile
      const user = {
        id: profile.id,
        name: profile.displayName,
        email: profile.emails?.[0]?.value,
        avatar: profile.photos?.[0]?.value,
        provider: "google",
      };
      
      console.log('‚úÖ User object created:', user);
      return done(null, user);
    }
  )
);

// Serialize user for session
passport.serializeUser((user, done) => {
  console.log('üíæ Serializing user for session:', user);
  done(null, user);
});

// Deserialize user from session
passport.deserializeUser((user, done) => {
  console.log('üîì Deserializing user from session:', user);
  done(null, user);
});

// Auth middleware
const requireAuth = (req, res, next) => {
  if (req.isAuthenticated()) {
    return next();
  }
  res.status(401).json({ error: "Authentication required" });
};

// Helper function to add citations to Gemini responses using grounding metadata
function addCitations(text, groundingMetadata) {
  if (
    !groundingMetadata?.groundingSupports ||
    !groundingMetadata?.groundingChunks
  ) {
    return text;
  }

  const supports = groundingMetadata.groundingSupports;
  const chunks = groundingMetadata.groundingChunks;

  // Sort supports by end_index in descending order to avoid shifting issues when inserting
  const sortedSupports = [...supports].sort(
    (a, b) => (b.segment?.endIndex ?? 0) - (a.segment?.endIndex ?? 0)
  );

  let citedText = text;

  for (const support of sortedSupports) {
    const endIndex = support.segment?.endIndex;
    if (endIndex === undefined || !support.groundingChunkIndices?.length) {
      continue;
    }

    const citationLinks = support.groundingChunkIndices
      .map((i) => {
        const chunk = chunks[i];
        if (chunk?.web?.uri && chunk?.web?.title) {
          return `[${i + 1}: ${chunk.web.title}](${chunk.web.uri})`;
        }
        return null;
      })
      .filter(Boolean);

    if (citationLinks.length > 0) {
      const citationString = ` ${citationLinks.join(", ")}`;
      citedText =
        citedText.slice(0, endIndex) +
        citationString +
        citedText.slice(endIndex);
    }
  }

  // Add search queries used for transparency
  if (groundingMetadata.webSearchQueries?.length > 0) {
    citedText += `\n\n**Search queries used:** ${groundingMetadata.webSearchQueries.join(
      ", "
    )}`;
  }

  return citedText;
}

// Model driver implementations with search capabilities
const modelHandlers = {
  async gpt(prompt, context, useSearch = false) {
    try {
      if (!process.env.OPENAI_API_KEY) {
        throw new Error("OpenAI API key not configured");
      }

      const OpenAI = require("openai");
      const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

      console.log(
        `ü§ñ GPT request (${prompt.length} chars)${
          useSearch ? " with search" : ""
        }`
      );

      // Safely handle context and stepOutputs
      const safeContext = context || {};
      const safeStepOutputs = Array.isArray(safeContext.stepOutputs)
        ? safeContext.stepOutputs
        : [];
      const userInput = safeContext.userInput || "";

      const messages = [
        {
          role: "system",
          content:
            "You are a helpful AI assistant focused on providing practical, actionable responses with accurate, up-to-date information. When conducting research, always include proper source citations in format [Source: Publication Name, Article Title, Date, URL]. Stay focused on the user's specific request and avoid generic business language. Be engaging and creative while remaining helpful and direct.",
        },
        { role: "user", content: userInput },
      ];

      // Add step outputs as context (last 2 to avoid token limits)
      if (safeStepOutputs.length > 0) {
        const recentOutputs = safeStepOutputs.slice(-2);
        for (const output of recentOutputs) {
          if (output && typeof output === "string" && output.trim()) {
            messages.push({ role: "user", content: output });
          }
        }
      }

      // Add the current prompt
      messages.push({ role: "user", content: prompt });

      const requestConfig = {
        model: "gpt-4.1",
        tools: [{ type: "web_search_preview" }],
        input:
          prompt +
          "\nBased on the following context:\n" +
          messages.map((m) => `${m.role}: ${m.content}`).join("\n"),
      };

      const res = await openai.responses.create(requestConfig);

      const content = res.output[res.output.length - 1].content;
      const text = content.text || res.output_text;
      const citations =
        content.annotations?.map(
          (a) =>
            `[${a.type}] ${a.title} - ${a.url} (${a.start_index} - ${a.end_index})`
        ) || [];

      return `${text}\n\n${citations?.join("\n")}`;
    } catch (error) {
      console.error("GPT API error:", error);
      return "GPT API error: " + error.message;
    }
  },

  async claude(prompt, context, useSearch = false) {
    try {
      if (!process.env.ANTHROPIC_API_KEY) {
        throw new Error("Anthropic API key not configured");
      }

      const anthropic = new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY,
      });

      console.log(
        `üß† Claude request (${prompt.length} chars)${
          useSearch ? " with search and thinking" : ""
        }`
      );

      // Determine system prompt
      const isFinalArticleStep =
        prompt.includes("ultimate-final-article") ||
        prompt.includes(
          "DELIVER ONLY the complete, final, publication-ready article content"
        ) ||
        prompt.includes("Begin the article immediately");

      const defaultSystemPrompt =
        "You are Claude, an AI assistant focused on logical analysis, accuracy, and clear reasoning. " +
        "When conducting research, always include proper source citations in format [Source: Publication Name, Article Title, Date, URL]. " +
        "When tackling complex requests, think step by step and show your reasoning as analysis, followed by a clear answer.";

      const finalArticlePrompt =
        "You are Claude, a master content creator. For final article production: DO NOT provide thinking, analysis, or meta-commentary. " +
        "DELIVER ONLY the complete, final article content. Begin immediately with the article title and content.";

      const systemPrompt = isFinalArticleStep
        ? finalArticlePrompt
        : defaultSystemPrompt;

      // Safely handle context and stepOutputs with better error handling
      const safeContext = context || {};
      const safeStepOutputs = Array.isArray(safeContext.stepOutputs)
        ? safeContext.stepOutputs
        : [];
      const userInput = safeContext.userInput || "";

      // Build messages array with proper content
      const messages = [{ role: "user", content: userInput }];

      // Add step outputs as context (last 2 to avoid token limits)
      if (safeStepOutputs.length > 0) {
        const recentOutputs = safeStepOutputs.slice(-2);
        for (const output of recentOutputs) {
          if (output && typeof output === "string" && output.trim()) {
            messages.push({ role: "user", content: output });
          }
        }
      }

      // Add the current prompt
      messages.push({ role: "user", content: prompt });

      // Filter out empty messages
      const filteredMessages = messages.filter(
        (msg) => msg.content && msg.content.trim()
      );

      const requestConfig = {
        model: "claude-opus-4-20250514",
        max_tokens: 32000,
        system: systemPrompt,
        messages: filteredMessages,
        tools: [
          {
            name: "web_search",
            type: "web_search_20250305",
          },
        ],
        thinking: {
          type: "enabled",
          budget_tokens: 31999,
        },
      };

      // Send request as a streaming response
      const response = await anthropic.messages.create(requestConfig);

      console.log("üß† Claude response:", response);
      const msg = response.content
        .filter((c) => c.type === "text")
        .map((c) => c.text)
        .join("\n");

      return msg;
    } catch (error) {
      console.error("Claude API error:", error);
      return "Claude API error: " + error.message;
    }
  },

  async gemini(prompt, context, useSearch = false) {
    // -- Updated implementation using @google/genai official SDK with Google Search grounding --
    try {
      if (!process.env.GEMINI_API_KEY) {
        throw new Error("Gemini API key not configured");
      }

      console.log(
        `üíé Gemini request (${prompt.length} chars)${
          useSearch ? " with Google Search grounding" : ""
        }`
      );

      // Lazy-load the SDK to avoid cost if Gemini is disabled
      const { GoogleGenAI } = require("@google/genai");

      const ai = new GoogleGenAI({
        apiKey: process.env.GEMINI_API_KEY,
      });

      const modelName = "gemini-2.5-flash"; // Use Flash for better performance with grounding

      // Build config with Google Search grounding when needed
      const config = {
        temperature: 1.05,
        thinkingConfig: {
          thinkingBudget: -1,
        },
        responseMimeType: "text/plain",
      };

      // Add Google Search grounding tool if search is requested
      if (useSearch) {
        config.tools = [
          {
            googleSearch: {},
          },
        ];
        console.log("üîç Enabling Google Search grounding for Gemini");
      }

      // Combine context + prompt
      const combinedText = [
        context.userInput || "",
        ...context.stepOutputs.slice(-3),
        prompt,
      ]
        .filter(Boolean)
        .join("\n\n");

      const baseMessage = {
        role: "user",
        parts: [
          {
            text: combinedText,
          },
        ],
      };

      const requestParams = {
        model: modelName,
        config,
        contents: [baseMessage],
      };

      // --- Retry logic similar to previous implementation ---
      const { maxRetries, retryDelay, backoffMultiplier } =
        modelsConfig.retryPolicy;

      let attempt = 0;
      let delayMs = retryDelay;
      const sleep = (ms) => new Promise((res) => setTimeout(res, ms));

      let lastError;

      while (attempt <= maxRetries) {
        try {
          const stream = await ai.models.generateContentStream(requestParams);

          let fullText = "";
          let groundingMetadata = null;

          for await (const chunk of stream) {
            if (chunk.text) fullText += chunk.text;

            // Capture grounding metadata if available
            if (chunk.groundingMetadata) {
              groundingMetadata = chunk.groundingMetadata;
            }
          }

          if (!fullText.trim()) {
            throw new Error("No content returned from Gemini stream");
          }

          // If we have grounding metadata, add citations to the response
          if (useSearch && groundingMetadata) {
            const textWithCitations = addCitations(fullText, groundingMetadata);
            console.log(
              "‚úÖ Gemini response with Google Search grounding and citations"
            );
            return textWithCitations;
          }

          return fullText;
        } catch (err) {
          lastError = err;

          // Retry only on transient errors
          if (
            attempt < maxRetries &&
            ["ECONNRESET", "ETIMEDOUT"].includes(err.code) // network level
          ) {
            console.warn(
              `‚ö†Ô∏è Gemini attempt #${attempt + 1} failed: ${
                err.message
              }. Retrying in ${delayMs} ms‚Ä¶`
            );
            await sleep(delayMs);
            delayMs *= backoffMultiplier;
            attempt += 1;
            continue;
          }

          break; // non-retryable
        }
      }

      console.error("‚ùå Gemini failed:", lastError?.message || lastError);

      return "Gemini API error: " + (lastError?.message || "Unknown error");
    } catch (error) {
      console.error("Gemini API setup error:", error);
      return "Gemini API error: " + error.message;
    }
  },

  async grok(prompt, context, useSearch = false) {
    try {
      if (!process.env.GROK_API_KEY) {
        // Fallback to Gemini if available
        if (process.env.GEMINI_API_KEY) {
          console.log(
            "üîÑ Grok unavailable, falling back to Gemini with search"
          );
          return await modelHandlers.gemini(
            `Acting as Grok with real-time research capabilities: ${prompt}`,
            context,
            useSearch
          );
        }
        throw new Error(
          "Grok API key not configured and no fallback available"
        );
      }

      const axios = require("axios");
      console.log(
        `‚ö° Grok request (${prompt.length} chars)${
          useSearch ? " with deep search" : ""
        }`
      );

      const requestConfig = {
        model: "grok-3",
        system:
          "You are Grok, an AI with real-time information access and a witty personality. When conducting research, always include proper source citations in format [Source: Publication Name, Article Title, Date, URL]. Focus on STEM/math reasoning, live social-web research, and chain-of-thought analysis. Provide current, accurate information while staying focused on the user's specific request.",
        messages: [
          {
            role: "user",
            content: context.userInput,
          },
          ...context.stepOutputs
            .slice(-3)
            .map((c) => ({ role: "user", content: c })),
          {
            role: "user",
            content: prompt,
          },
          {
            role: "user",
            content: prompt,
          },
        ],
        temperature: 1,
        stream: false,
      };

      // Note: Grok may have native search without explicit tool configuration
      // The search capability is inherent to the model itself

      const response = await axios.post(
        "https://api.x.ai/v1/chat/completions",
        requestConfig,
        {
          headers: {
            Authorization: `Bearer ${process.env.GROK_API_KEY}`,
            "Content-Type": "application/json",
          },
        }
      );

      return response.data.choices[0].message.content;
    } catch (error) {
      console.error("Grok API error:", error);
      return "Grok API error: " + error.message;
    }
  },
};

// Workflow configuration
const modelsConfig = {
  stepOverrides: {
    article: {
      "clarify-brief": "gpt",
      "deep-research": "gemini",
      "first-draft": "gpt",
      "strengths-analysis": "grok",
      "initial-structure": "gpt",
      "logical-enhancement": "claude",
      "creative-polish": "gpt",
      "final-logic-check": "claude",
      "production-ready": "gpt",
    },
    email: {
      "decode-request": "gpt",
      "validate-response": "gemini",
      "craft-response": "gpt",
    },
    research: {
      "clarify-scope": "gpt",
      "broad-research": "gemini",
      "structure-findings": "gpt",
      "deep-dive-research": "gemini",
      "logical-analysis": "claude",
      "strategic-synthesis": "gpt",
      "final-report": "claude",
    },
  },
  fallbacks: {
    grok: "gemini",
    gemini: "gpt",
    claude: "gpt",
    gpt: null,
  },
  enabledDrivers: {
    gpt: true,
    claude: true,
    gemini: true,
    grok: true, // Now enabled by default since it's working
    "google-search": true, // Special validation step
    "all-models": true, // Special validation step
  },
  retryPolicy: {
    maxRetries: 3,
    retryDelay: 1000,
    backoffMultiplier: 2,
  },
  validationConfig: {
    googleSearchValidation: {
      maxParallelSearches: 5, // Max concurrent Google searches
      retryAttempts: 2, // Number of retries for each source validation
      invalidSourceThreshold: 0.1, // Percentage of invalid/questionable sources above which to warn
    },
  },
};

// Workflow Engine
class WorkflowEngine {
  resolveModel(stepModel, stepId, scenarioId) {
    // Check step-specific overrides first
    const stepOverrides = modelsConfig.stepOverrides[scenarioId];
    let targetModel = stepOverrides?.[stepId] || stepModel;

    // Handle special "all-models" validation step
    if (targetModel === "all-models") {
      return "all-models";
    }

    // Handle special "google-search" validation step
    if (targetModel === "google-search") {
      return "google-search";
    }

    // Apply fallback logic if the target model is disabled
    while (targetModel && !modelsConfig.enabledDrivers[targetModel]) {
      const fallback = modelsConfig.fallbacks[targetModel];
      if (fallback === null) {
        return null; // No more fallbacks available
      }
      targetModel = fallback;
      console.log(
        `üîÑ Model ${stepModel} disabled, falling back to ${targetModel}`
      );
    }

    return targetModel;
  }

  renderPrompt(template, context) {
    let rendered = template;

    // Replace {{userInput}} placeholder
    if (context.userInput) {
      rendered = rendered.replace(/\{\{userInput\}\}/g, context.userInput);
    }

    // Replace {{stepN}} placeholders with previous outputs
    if (Array.isArray(context.stepOutputs)) {
      context.stepOutputs.forEach((output, index) => {
        if (output && output.trim()) {
          const placeholder = `{{step${index + 1}}}`;
          rendered = rendered.replace(
            new RegExp(placeholder.replace(/[{}]/g, "\\$&"), "g"),
            output
          );
        }
      });
    }

    // Handle validation-specific placeholders
    if (context.validationResults) {
      rendered = rendered.replace(
        /\{\{gptValidation\}\}/g,
        context.validationResults.gpt || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{claudeValidation\}\}/g,
        context.validationResults.claude || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{geminiValidation\}\}/g,
        context.validationResults.gemini || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{grokValidation\}\}/g,
        context.validationResults.grok || "No assessment"
      );
      rendered = rendered.replace(
        /\{\{originalContent\}\}/g,
        context.originalContent || "No content"
      );
    }

    // Replace {{content}} with the latest output for validation steps
    if (Array.isArray(context.stepOutputs) && context.stepOutputs.length > 0) {
      const latestOutput = context.stepOutputs[context.stepOutputs.length - 1];
      rendered = rendered.replace(/\{\{content\}\}/g, latestOutput || "");
    }

    return rendered;
  }

  // Determine if a step should use search capabilities
  shouldUseSearch(stepId, prompt) {
    // Steps that definitely need search
    const searchRequiredSteps = [
      "deep-research",
      "validate-response",
      "broad-research",
      "deep-dive-research",
      "multi-model-source-validation",
      "final-source-verification",
    ];

    // Keywords that indicate search should be used
    const searchKeywords = [
      "current",
      "latest",
      "recent",
      "up-to-date",
      "trending",
      "statistics",
      "data",
      "research",
      "sources",
      "verify",
      "validate",
      "fact-check",
      "confirm",
      "investigate",
      "WITH SOURCES",
      "CRITICAL:",
      "citations",
      "references",
    ];

    // Check if step requires search
    if (searchRequiredSteps.includes(stepId)) {
      return true;
    }

    // Check if prompt contains search-indicating keywords
    const lowerPrompt = prompt.toLowerCase();
    return searchKeywords.some((keyword) =>
      lowerPrompt.includes(keyword.toLowerCase())
    );
  }

  async executeMultiModelValidation(prompt, context) {
    console.log(`üîç Starting ENHANCED multi-model source validation with advanced search`);

    // Enhanced validation configuration with specialized prompts
    const validationConfig = {
      gpt: `You are GPT, an expert fact-checker with web search capabilities. Perform comprehensive source validation and fact-checking.

CONTENT TO VALIDATE: {{content}}

ENHANCED VALIDATION PROTOCOL:
1. SOURCE AUTHENTICITY
   - Verify each source exists and is legitimate
   - Check if sources are being cited accurately
   - Identify any fabricated or questionable sources

2. FACTUAL ACCURACY ASSESSMENT
   - Cross-check all statistical claims against multiple sources
   - Verify dates, numbers, and specific facts
   - Identify any outdated or incorrect information

3. LOGICAL CONSISTENCY ANALYSIS
   - Check for internal contradictions
   - Verify cause-effect relationships claimed
   - Assess reasoning quality and logical flow

4. BIAS & MISINFORMATION DETECTION
   - Identify potential bias in source selection
   - Look for signs of selective fact presentation
   - Flag any known misinformation patterns

ENHANCED ASSESSMENT FORMAT:
OVERALL_CONFIDENCE: [1-10]
SOURCE_AUTHENTICITY: [Verified/Questionable/Invalid sources identified]
FACTUAL_ACCURACY: [Specific claims verified/contradicted]
LOGICAL_CONSISTENCY: [Assessment of reasoning quality]
BIAS_INDICATORS: [Any bias patterns detected]
MISINFORMATION_FLAGS: [Potential misinformation identified]
VERIFICATION_EVIDENCE: [Search results supporting assessment]
IMPROVEMENT_RECOMMENDATIONS: [Specific suggestions for better sourcing]`,

      claude: `You are Claude, a meticulous source reliability analyst with thinking and web search capabilities. Conduct deep analysis of source credibility and reasoning.

CONTENT TO VALIDATE: {{content}}

ADVANCED ANALYSIS REQUIREMENTS:
1. SOURCE CREDIBILITY MATRIX
   - Evaluate each source's reputation and reliability
   - Assess author credentials and expertise
   - Check for conflicts of interest or bias

2. EVIDENCE QUALITY ASSESSMENT
   - Analyze methodology behind cited studies
   - Evaluate sample sizes and research quality
   - Check for peer review and replication

3. REASONING ARCHITECTURE REVIEW
   - Examine argument structure and logic
   - Identify assumptions and unsupported leaps
   - Assess evidence-to-conclusion ratios

4. CROSS-REFERENCE VALIDATION
   - Compare claims against multiple independent sources
   - Look for consensus or significant disagreement
   - Identify any outlier claims needing verification

DETAILED ANALYSIS FORMAT:
RELIABILITY_MATRIX: [Source-by-source credibility assessment]
EVIDENCE_QUALITY: [Methodology and research quality evaluation]
REASONING_STRUCTURE: [Logic and argument analysis]
CROSS_VALIDATION: [Independent source confirmation]
CREDIBILITY_CONCERNS: [Specific reliability issues identified]
SUPPORTING_EVIDENCE: [Search results confirming analysis]
ENHANCEMENT_PRIORITIES: [Key areas needing improvement]`,

      gemini: `You are Gemini, a comprehensive research validator with Google grounding search. Leverage your massive context and search capabilities for thorough verification.

CONTENT TO VALIDATE: {{content}}

COMPREHENSIVE VERIFICATION PROTOCOL:
1. MASSIVE SCALE CROSS-REFERENCING
   - Search across thousands of sources for each claim
   - Compare against academic databases and repositories
   - Verify against government and institutional sources

2. TEMPORAL ACCURACY VERIFICATION
   - Check if information is current and up-to-date
   - Identify any superseded or outdated claims
   - Verify timeline accuracy for historical claims

3. EXPERT CONSENSUS ANALYSIS
   - Search for expert opinions and scientific consensus
   - Identify any controversial or disputed claims
   - Check for recent developments affecting validity

4. INSTITUTIONAL SOURCE VALIDATION
   - Verify credentials of institutions cited
   - Check for any retractions or corrections
   - Assess institutional reputation and standing

COMPREHENSIVE ASSESSMENT:
SCALE_VERIFICATION: [Large-scale cross-reference results]
TEMPORAL_ACCURACY: [Currency and timeline verification]
EXPERT_CONSENSUS: [Scientific/expert community alignment]
INSTITUTIONAL_VALIDATION: [Institutional source credibility]
DISPUTED_CLAIMS: [Any controversial or disputed information]
SEARCH_EVIDENCE: [Extensive search results summary]
VERIFICATION_GAPS: [Areas needing additional verification]`,

      grok: `You are Grok, a real-time information specialist with advanced web search and current data access. Focus on live verification and current developments.

CONTENT TO VALIDATE: {{content}}

REAL-TIME VALIDATION FOCUS:
1. CURRENT EVENT VERIFICATION
   - Check latest news and developments
   - Verify any claims about recent events
   - Identify any rapidly changing information

2. LIVE DATA VALIDATION
   - Verify current statistics and metrics
   - Check for recent updates to data cited
   - Identify any market or trend changes affecting claims

3. SOCIAL PROOF & SENTIMENT ANALYSIS
   - Check current social media and public discourse
   - Identify any ongoing debates or controversies
   - Assess current expert opinions and reactions

4. BREAKING DEVELOPMENT IMPACT
   - Search for any recent developments affecting claims
   - Check for breaking news that might contradict content
   - Identify any emerging trends or new information

REAL-TIME ASSESSMENT:
CURRENT_ACCURACY: [Real-time verification of recent claims]
LIVE_DATA_CHECK: [Current statistics and data verification]
SOCIAL_VALIDATION: [Public discourse and expert sentiment]
RECENT_DEVELOPMENTS: [Any breaking news or updates affecting content]
TREND_ANALYSIS: [Current trends supporting or contradicting claims]
LIVE_EVIDENCE: [Real-time search results and verification]
URGENCY_FLAGS: [Any urgent corrections or updates needed]`
    };

    const models = ["gpt", "claude", "gemini", "grok"];
    const validationResults = {};
    const detailedAssessments = {};

    // Run enhanced validation in parallel with specialized focus
    const validationPromises = models
      .filter((model) => modelsConfig.enabledDrivers[model])
      .map(async (model) => {
        try {
          console.log(
            `üîç Running ENHANCED ${model.toUpperCase()} validation with specialized search`
          );
          
          const validationPrompt = this.renderPrompt(
            validationConfig[model],
            context
          );
          
          // Use search for all validation models with longer timeout
          const startTime = Date.now();
          const result = await modelHandlers[model](
            validationPrompt,
            context,
            true
          );
          const duration = Date.now() - startTime;

          validationResults[model] = result;
          
          // Extract structured assessment data
          detailedAssessments[model] = {
            model: model.toUpperCase(),
            result: result,
            duration: duration,
            length: result.length,
            timestamp: new Date().toISOString(),
            focus: this.getModelValidationFocus(model)
          };

          console.log(
            `‚úÖ ENHANCED ${model.toUpperCase()} validation complete (${duration}ms, ${result.length} chars)`
          );
        } catch (error) {
          console.error(
            `‚ùå ENHANCED ${model.toUpperCase()} validation failed:`,
            error.message
          );
          validationResults[model] = `Enhanced validation failed: ${error.message}`;
          detailedAssessments[model] = {
            model: model.toUpperCase(),
            result: `Validation failed: ${error.message}`,
            duration: 0,
            error: error.message,
            timestamp: new Date().toISOString()
          };
        }
      });

    await Promise.all(validationPromises);

    // Enhanced result synthesis
    const synthesisPrompt = `You are a master validation synthesizer. Analyze and synthesize the results from multiple AI model validations.

VALIDATION RESULTS:
${Object.entries(validationResults).map(([model, result]) => `
${model.toUpperCase()} VALIDATION:
${result}
---`).join('\n')}

SYNTHESIS REQUIREMENTS:
1. Identify consensus across models
2. Highlight any disagreements or contradictions
3. Assess overall confidence in content validity
4. Prioritize most critical issues identified
5. Provide actionable recommendations

SYNTHESIS FORMAT:
CONSENSUS_FINDINGS: [Points where all models agree]
DISAGREEMENTS: [Areas where models disagree]
CONFIDENCE_ASSESSMENT: [Overall confidence in content validity 1-10]
CRITICAL_ISSUES: [Most important problems identified]
SOURCE_RELIABILITY: [Overall assessment of sources used]
FACT_ACCURACY: [Factual accuracy assessment]
ACTIONABLE_RECOMMENDATIONS: [Specific steps to improve content]
VALIDATION_SUMMARY: [Executive summary of findings]`;

    const synthesis = await modelHandlers.claude(synthesisPrompt, {}, false);

    // Store enhanced validation results in context
    context.validationResults = validationResults;
    context.detailedAssessments = detailedAssessments;
    context.validationSynthesis = synthesis;
    context.originalContent = context.stepOutputs[context.stepOutputs.length - 1];

    // Return enhanced validation summary
    const summaryText = `ENHANCED Multi-Model Source Validation Complete:

üîç VALIDATION SCOPE: ${Object.keys(validationResults).length} AI models with specialized search
üìä TOTAL ANALYSIS: ${Object.values(validationResults).reduce((sum, result) => sum + result.length, 0)} characters of detailed assessment

${synthesis}

üìã DETAILED MODEL ASSESSMENTS:
${Object.entries(detailedAssessments)
  .map(([model, assessment]) => 
    `${assessment.model}: ${assessment.focus} (${assessment.length} chars, ${assessment.duration}ms)`
  ).join('\n')}

‚úÖ Enhanced validation synthesis complete with actionable recommendations.`;

    return summaryText;
  }

  // NEW: Get model validation focus description
  getModelValidationFocus(model) {
    const focusMap = {
      'gpt': 'Fact-checking & logical consistency',
      'claude': 'Source credibility & reasoning analysis', 
      'gemini': 'Large-scale cross-referencing & institutional validation',
      'grok': 'Real-time verification & current developments'
    };
    return focusMap[model] || 'General validation';
  }

  // ENHANCED: Extract sources from content using comprehensive patterns
  extractSourcesFromContent(content) {
    // Handle undefined or null content
    if (!content || typeof content !== "string") {
      console.log(`‚ö†Ô∏è No valid content provided for source extraction`);
      return [];
    }

    const sources = new Set();
    const extractedSources = [];

    // Pattern 1: URLs (http/https) with context
    const urlPattern = /https?:\/\/[^\s\)\]\}\<\>\n]+/g;
    const urls = content.match(urlPattern) || [];
    urls.forEach((url) => {
      const cleanUrl = url.replace(/[.,;:!?]*$/, "");
      sources.add(cleanUrl);
      extractedSources.push({
        source: cleanUrl,
        type: 'url',
        pattern: 'direct_link',
        confidence: 0.9
      });
    });

    // Pattern 2: [Source: ...] format (enhanced)
    const sourcePattern1 = /\[Source:\s*([^\]]+)\]/gi;
    const sourceMatches1 = content.matchAll(sourcePattern1);
    for (const match of sourceMatches1) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'citation',
        pattern: 'bracket_source',
        confidence: 0.95
      });
    }

    // Pattern 3: (Source: ...) format (enhanced)
    const sourcePattern2 = /\(Source:\s*([^\)]+)\)/gi;
    const sourceMatches2 = content.matchAll(sourcePattern2);
    for (const match of sourceMatches2) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'citation',
        pattern: 'paren_source',
        confidence: 0.95
      });
    }

    // Pattern 4: "According to [source]" (enhanced)
    const accordingPattern = /According to\s+([^,.\n]{5,100})/gi;
    const accordingMatches = content.matchAll(accordingPattern);
    for (const match of accordingMatches) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'attribution',
        pattern: 'according_to',
        confidence: 0.85
      });
    }

    // Pattern 5: "As reported by [source]" (enhanced)
    const reportedPattern = /As reported by\s+([^,.\n]{5,100})/gi;
    const reportedMatches = content.matchAll(reportedPattern);
    for (const match of reportedMatches) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'attribution',
        pattern: 'reported_by',
        confidence: 0.85
      });
    }

    // Pattern 6: [Author/Publication] states/reports/claims (enhanced)
    const authorPattern = /([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*(?:\s+(?:University|Institute|Foundation|Corporation|Company|Organization|Journal|Magazine|Times|Post|News))?)\s+(?:states|reports|claims|found|discovered|published|concluded|determined)/gi;
    const authorMatches = content.matchAll(authorPattern);
    for (const match of authorMatches) {
      const source = match[1].trim();
      if (source.length > 3 && source.length < 80) {
        sources.add(source);
        extractedSources.push({
          source,
          type: 'author_citation',
          pattern: 'author_verb',
          confidence: 0.75
        });
      }
    }

    // Pattern 7: Study/Research/Report references (enhanced)
    const studyPattern = /(?:study|research|report|paper|article|survey|analysis)\s+(?:by|from|published by|conducted by)\s+([^,.\n]{5,100})/gi;
    const studyMatches = content.matchAll(studyPattern);
    for (const match of studyMatches) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'study_citation',
        pattern: 'study_reference',
        confidence: 0.80
      });
    }

    // Pattern 8: Journal and academic citations
    const journalPattern = /(Journal of [^,.\n]{5,80}|[A-Z][a-z]+\s+Journal|Nature|Science|Cell|The Lancet|NEJM|Harvard Business Review)/gi;
    const journalMatches = content.matchAll(journalPattern);
    for (const match of journalMatches) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'journal_citation',
        pattern: 'academic_journal',
        confidence: 0.90
      });
    }

    // Pattern 9: Data from [source] patterns
    const dataPattern = /(?:data from|statistics from|information from|figures from)\s+([^,.\n]{5,100})/gi;
    const dataMatches = content.matchAll(dataPattern);
    for (const match of dataMatches) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'data_citation',
        pattern: 'data_from',
        confidence: 0.85
      });
    }

    // Pattern 10: Research by/from organization patterns
    const orgPattern = /(?:research by|study by|report from|data from)\s+([A-Z][a-zA-Z\s&]{5,80}(?:Inc|LLC|Corp|Organization|Institute|Foundation|University|College))/gi;
    const orgMatches = content.matchAll(orgPattern);
    for (const match of orgMatches) {
      const source = match[1].trim();
      sources.add(source);
      extractedSources.push({
        source,
        type: 'organization_citation',
        pattern: 'org_research',
        confidence: 0.88
      });
    }

    // Pattern 11: Expert quotes with attribution
    const expertPattern = /([A-Z][a-z]+\s+[A-Z][a-z]+),\s+(?:CEO|CTO|Director|Professor|Researcher|Analyst|Expert|Scientist|Author)\s+(?:at|of|from)\s+([^,.\n]{3,50})/gi;
    const expertMatches = content.matchAll(expertPattern);
    for (const match of expertMatches) {
      const source = `${match[1]}, ${match[2]}`;
      sources.add(source);
      extractedSources.push({
        source,
        type: 'expert_citation',
        pattern: 'expert_quote',
        confidence: 0.82
      });
    }

    const sourceArray = Array.from(sources).filter((source) => source.length > 2);
    
    console.log(`üîç Extracted ${sourceArray.length} sources from content using ${extractedSources.length} pattern matches`);
    console.log(`üìä Source pattern breakdown: ${this.getSourcePatternBreakdown(extractedSources)}`);
    
    return sourceArray;
  }

  // NEW: Get breakdown of source patterns for analysis
  getSourcePatternBreakdown(extractedSources) {
    const breakdown = {};
    extractedSources.forEach(item => {
      breakdown[item.pattern] = (breakdown[item.pattern] || 0) + 1;
    });
    return Object.entries(breakdown).map(([pattern, count]) => `${pattern}:${count}`).join(', ');
  }

  // ENHANCED: Validate a single source using advanced multi-step validation
  async validateSingleSource(source, originalContent, retryAttempts = 2) {
    const config = modelsConfig.validationConfig.googleSearchValidation;

    for (let attempt = 0; attempt < retryAttempts; attempt++) {
      try {
        console.log(
          `üîç Advanced validating source: "${source}" (attempt ${attempt + 1})`
        );

        // Step 1: Initial credibility assessment based on source characteristics
        const credibilityScore = this.assessSourceCredibility(source);

        // Step 2: Multi-query search strategy
        const searchQueries = [
          `"${source}" reliability credibility verification`,
          `"${source}" fact check accuracy review`,
          `"${source}" bias check media literacy`,
          `${source} site:wikipedia.org OR site:mediabiasfactcheck.com OR site:allsides.com`
        ];

        const searchResults = [];
        for (const query of searchQueries) {
          try {
            const result = await this.searchWeb(query);
            searchResults.push({ query, result });
          } catch (error) {
            console.log(`‚ö†Ô∏è Search query failed: ${query}`);
          }
        }

        // Step 3: Advanced analysis using multiple validation approaches
        const validationPrompt = `You are an expert fact-checker and source validation specialist with access to multiple search results. Validate this source using comprehensive analysis.

        SOURCE TO VALIDATE: "${source}"
        INITIAL CREDIBILITY SCORE: ${credibilityScore.score}/100 (${credibilityScore.reasoning})
        ORIGINAL CONTEXT: ${originalContent.substring(0, 500)}...
        
        SEARCH RESULTS FROM MULTIPLE QUERIES:
        ${searchResults.map((sr, i) => `Query ${i+1}: ${sr.query}\nResults: ${sr.result}\n---`).join('\n')}
        
        COMPREHENSIVE VALIDATION REQUIREMENTS:
        1. Source Existence & Authentication
           - Does this source actually exist?
           - Is it a real publication/organization/person?
           - Are there any signs of fabrication?
        
        2. Credibility & Reliability Assessment
           - What is the source's reputation in its field?
           - What do fact-checkers say about this source?
           - Any known bias or reliability issues?
        
        3. Content Verification
           - Does the source contain information relevant to the context?
           - Is the source being cited accurately?
           - Are there contradictory reports about this source?
        
        4. Red Flags & Warning Signs
           - Any known misinformation history?
           - Questionable funding or affiliations?
           - Consistent criticism from experts?
        
        5. Cross-Reference Validation
           - How do other sources rate this source?
           - Independent verification available?
           - Consensus among multiple validators?
        
        ENHANCED ASSESSMENT FORMAT:
        STATUS: [VERIFIED/QUESTIONABLE/INVALID/ERROR]
        CONFIDENCE: [1-10] (where 10 = absolutely certain)
        CREDIBILITY_RATING: [1-100] (overall source credibility)
        EXISTENCE_CONFIRMED: [Yes/No/Unclear]
        BIAS_LEVEL: [Low/Moderate/High/Extreme]
        FACT_CHECK_RATING: [Excellent/Good/Mixed/Poor/Terrible]
        REASON: [Detailed explanation of assessment]
        EVIDENCE: [Key findings from search results]
        RED_FLAGS: [List any concerning issues found]
        CROSS_REFERENCES: [Other sources that validate or contradict]
        RECOMMENDATION: [KEEP_WITH_CONFIDENCE/KEEP_WITH_CAUTION/VERIFY_FURTHER/REMOVE]
        RELIABILITY_FACTORS: [List factors affecting reliability]`;

        // Use Claude for deep analysis
        const analysis = await modelHandlers.claude(validationPrompt, {}, false);

        // Enhanced parsing with better error handling
        const parseField = (fieldName, pattern, defaultValue) => {
          const match = analysis.match(new RegExp(`${fieldName}:\\s*([^\n]+)`, 'i'));
          return match ? match[1].trim() : defaultValue;
        };

        const validation = {
          source,
          status: parseField('STATUS', '', 'QUESTIONABLE'),
          confidence: parseInt(parseField('CONFIDENCE', '', '5')),
          credibilityRating: parseInt(parseField('CREDIBILITY_RATING', '', '50')),
          existenceConfirmed: parseField('EXISTENCE_CONFIRMED', '', 'Unclear'),
          biasLevel: parseField('BIAS_LEVEL', '', 'Unknown'),
          factCheckRating: parseField('FACT_CHECK_RATING', '', 'Unknown'),
          reason: parseField('REASON', '', 'Unable to determine'),
          evidence: parseField('EVIDENCE', '', 'No evidence found'),
          redFlags: parseField('RED_FLAGS', '', 'None identified'),
          crossReferences: parseField('CROSS_REFERENCES', '', 'None found'),
          recommendation: parseField('RECOMMENDATION', '', 'VERIFY_FURTHER'),
          reliabilityFactors: parseField('RELIABILITY_FACTORS', '', 'Unknown'),
          searchQueries: searchQueries,
          initialCredibilityScore: credibilityScore,
          fullAnalysis: analysis,
          validationTimestamp: new Date().toISOString()
        };

        console.log(`‚úÖ Advanced validation complete for "${source}": ${validation.status} (${validation.confidence}/10 confidence)`);
        return validation;

      } catch (error) {
        console.error(`‚ùå Error in advanced validation for "${source}":`, error.message);
        if (attempt === retryAttempts - 1) {
          return {
            source,
            status: "ERROR",
            confidence: 0,
            credibilityRating: 0,
            reason: `Advanced validation failed: ${error.message}`,
            evidence: "",
            recommendation: "VERIFY_FURTHER",
            searchQueries: [],
            initialCredibilityScore: { score: 0, reasoning: "Validation error" },
            validationTimestamp: new Date().toISOString()
          };
        }
        // Wait before retry
        await new Promise((resolve) => setTimeout(resolve, 2000));
      }
    }
  }

  // NEW: Assess initial source credibility based on characteristics
  assessSourceCredibility(source) {
    let score = 50; // Start with neutral score
    const factors = [];

    // Check if it's a URL
    if (source.match(/^https?:\/\//)) {
      const domain = source.match(/https?:\/\/(?:www\.)?([^\/]+)/)?.[1];
      if (domain) {
        // High credibility domains
        const highCredibilityDomains = [
          'nature.com', 'science.org', 'nejm.org', 'thelancet.com', 'cell.com',
          'pubmed.ncbi.nlm.nih.gov', 'scholar.google.com', 'arxiv.org',
          'who.int', 'cdc.gov', 'fda.gov', 'nih.gov', 'nasa.gov',
          'reuters.com', 'ap.org', 'bbc.com', 'npr.org', 'pbs.org',
          'edu', '.gov', '.org'
        ];

        // Medium credibility domains
        const mediumCredibilityDomains = [
          'nytimes.com', 'washingtonpost.com', 'wsj.com', 'economist.com',
          'ft.com', 'guardian.com', 'cnn.com', 'cnbc.com', 'bloomberg.com'
        ];

        // Low credibility indicators
        const lowCredibilityIndicators = [
          'wordpress.com', 'blogspot.com', 'medium.com', 'substack.com',
          'facebook.com', 'twitter.com', 'youtube.com', 'reddit.com'
        ];

        if (highCredibilityDomains.some(d => domain.includes(d))) {
          score += 30;
          factors.push('High-credibility domain');
        } else if (mediumCredibilityDomains.some(d => domain.includes(d))) {
          score += 15;
          factors.push('Established media domain');
        } else if (lowCredibilityIndicators.some(d => domain.includes(d))) {
          score -= 20;
          factors.push('Social media or blog platform');
        }

        // HTTPS bonus
        if (source.startsWith('https://')) {
          score += 5;
          factors.push('Secure connection');
        }
      }
    }

    // Check for academic/institutional indicators
    const academicIndicators = [
      'University', 'Institute', 'College', 'Academy', 'Research',
      'Journal of', 'Harvard', 'MIT', 'Stanford', 'Oxford', 'Cambridge',
      'Nature', 'Science', 'Cell', 'NEJM', 'Lancet'
    ];

    if (academicIndicators.some(indicator => source.includes(indicator))) {
      score += 25;
      factors.push('Academic/institutional source');
    }

    // Check for government indicators
    const govIndicators = [
      'Department of', 'Ministry of', 'Bureau of', 'Agency', 'Commission',
      'CDC', 'FDA', 'WHO', 'NASA', 'NOAA', 'EPA'
    ];

    if (govIndicators.some(indicator => source.includes(indicator))) {
      score += 20;
      factors.push('Government agency');
    }

    // Check for news organization indicators
    const newsIndicators = [
      'Times', 'Post', 'Herald', 'Tribune', 'Journal', 'News',
      'Reuters', 'Associated Press', 'Bloomberg', 'BBC'
    ];

    if (newsIndicators.some(indicator => source.includes(indicator))) {
      score += 10;
      factors.push('News organization');
    }

    // Check for warning signs
    const warningIndicators = [
      'conspiracy', 'exposed', 'shocking', 'secret', 'hidden truth',
      'mainstream media', 'big pharma', 'fake news'
    ];

    if (warningIndicators.some(indicator => source.toLowerCase().includes(indicator.toLowerCase()))) {
      score -= 30;
      factors.push('Contains conspiracy language');
    }

    // Check for very short or vague sources
    if (source.length < 10) {
      score -= 20;
      factors.push('Very short/vague source');
    }

    // Ensure score stays within bounds
    score = Math.max(0, Math.min(100, score));

    return {
      score,
      reasoning: factors.length > 0 ? factors.join('; ') : 'No specific indicators found',
      factors
    };
  }

  // NEW: Execute Google search validation for all sources
  async executeGoogleSearchValidation(prompt, context) {
    console.log(`üåê Starting Google search validation for all sources`);

    const config = modelsConfig.validationConfig.googleSearchValidation;
    const currentContent = context.stepOutputs[context.stepOutputs.length - 1];

    // Extract all sources from the content
    const sources = this.extractSourcesFromContent(currentContent);

    if (sources.length === 0) {
      console.log(`‚ÑπÔ∏è No sources found in content for validation`);

      // Clean content by removing all reference patterns
      const cleanedContent = this.removeAllReferences(currentContent);

      // Store empty results in context for final verification
      context.googleSearchValidation = {
        totalSources: 0,
        validationResults: [],
        validSources: [],
        invalidSources: [],
        questionableSources: [],
        errorSources: [],
        invalidPercentage: 0,
        flaggedSources: [],
        cleanedContent: cleanedContent,
        timestamp: new Date().toISOString(),
      };

      return `Google Search Validation Report:

üìä SUMMARY:
- Total sources found: 0
- No sources to validate
- Content cleaned of reference patterns

‚úÖ CLEANED CONTENT:
The content has been cleaned to remove any reference patterns and citation language. Here's the fact-based version:

${cleanedContent}

‚úÖ All reference language has been removed. Content now presents facts without citation claims.`;
    }

    console.log(
      `üîç Found ${sources.length} sources to validate via Google search`
    );

    // Limit the number of parallel searches to avoid overwhelming the API
    const maxParallel = Math.min(sources.length, config.maxParallelSearches);
    const sourceChunks = [];

    for (let i = 0; i < sources.length; i += maxParallel) {
      sourceChunks.push(sources.slice(i, i + maxParallel));
    }

    const validationResults = [];

    // Process sources in chunks to manage API rate limits
    for (const chunk of sourceChunks) {
      console.log(`üîç Processing chunk of ${chunk.length} sources`);

      const chunkPromises = chunk.map((source) =>
        this.validateSingleSource(source, currentContent, config.retryAttempts)
      );

      try {
        const chunkResults = await Promise.all(chunkPromises);
        validationResults.push(...chunkResults);

        // Brief pause between chunks
        if (sourceChunks.length > 1) {
          await new Promise((resolve) => setTimeout(resolve, 1000));
        }
      } catch (error) {
        console.error(`‚ùå Error processing source chunk:`, error.message);
      }
    }

    // Analyze results
    const validSources = validationResults.filter((r) => r.status === "VALID");
    const invalidSources = validationResults.filter(
      (r) => r.status === "INVALID"
    );
    const questionableSources = validationResults.filter(
      (r) => r.status === "QUESTIONABLE"
    );
    const errorSources = validationResults.filter((r) => r.status === "ERROR");

    const invalidPercentage =
      (invalidSources.length + questionableSources.length) /
      validationResults.length;

    console.log(`üìä Google search validation complete:
    - Valid: ${validSources.length}
    - Invalid: ${invalidSources.length}
    - Questionable: ${questionableSources.length}
    - Errors: ${errorSources.length}
    - Invalid percentage: ${Math.round(invalidPercentage * 100)}%`);

    // If no sources are valid or too many are invalid, clean the content
    let cleanedContent = currentContent;
    if (validSources.length === 0 || invalidPercentage > 0.5) {
      console.log(`üßπ Cleaning content due to insufficient valid sources`);
      cleanedContent = this.removeAllReferences(currentContent);
    }

    // Store results in context for final verification
    context.googleSearchValidation = {
      totalSources: sources.length,
      validationResults,
      validSources,
      invalidSources,
      questionableSources,
      errorSources,
      invalidPercentage,
      flaggedSources: [...invalidSources, ...questionableSources],
      cleanedContent: cleanedContent,
      timestamp: new Date().toISOString(),
    };

    // Generate summary report
    const summaryText = `Google Search Validation Report:
    
üìä SUMMARY:
- Total sources checked: ${sources.length}
- Valid sources: ${validSources.length}
- Invalid sources: ${invalidSources.length}
- Questionable sources: ${questionableSources.length}
- Validation errors: ${errorSources.length}
- Invalid percentage: ${Math.round(invalidPercentage * 100)}%

${
  validSources.length === 0 || invalidPercentage > 0.5
    ? `üßπ CONTENT CLEANED:
Since no sources could be validated or too many sources were invalid, all references have been removed. Here's the cleaned content:

${cleanedContent}

‚úÖ Content now presents facts without citation claims.`
    : `üö® FLAGGED SOURCES:
${[...invalidSources, ...questionableSources]
  .map((s) => `- "${s.source}" (${s.status}): ${s.reason}`)
  .join("\n")}

‚úÖ VERIFIED SOURCES:
${validSources
  .map((s) => `- "${s.source}" (Confidence: ${s.confidence}/10)`)
  .join("\n")}`
}

${
  invalidPercentage > config.invalidSourceThreshold
    ? `‚ö†Ô∏è WARNING: ${Math.round(
        invalidPercentage * 100
      )}% of sources are invalid/questionable (threshold: ${Math.round(
        config.invalidSourceThreshold * 100
      )}%)`
    : "‚úÖ Source reliability within acceptable thresholds"
}`;

    return summaryText;
  }

  // NEW: Web search helper method
  async searchWeb(query) {
    console.log(`üîç Searching web for: "${query}"`);

    try {
      // Use the most appropriate search-enabled model
      // Priority: Grok (native real-time) > Gemini (Google search) > Claude (web search)
      let searchModel = "grok";
      if (!modelsConfig.enabledDrivers.grok) {
        searchModel = modelsConfig.enabledDrivers.gemini ? "gemini" : "claude";
      }

      const searchPrompt = `Perform a web search for: "${query}"
      
      Please search for information about this query and provide:
      1. Key findings from the search results
      2. Relevant sources and URLs
      3. Credibility assessment of the sources found
      4. Any red flags or concerns about the information
      
      Focus on factual, verifiable information and note the reliability of sources.`;

      // Use the search-enabled model with search capability
      const result = await modelHandlers[searchModel](
        searchPrompt,
        {
          userInput: query,
          stepOutputs: [],
        },
        true
      ); // Enable search

      console.log(`‚úÖ Web search completed using ${searchModel.toUpperCase()}`);
      return result;
    } catch (error) {
      console.error(`‚ùå Web search failed:`, error.message);

      // Fallback to a basic search result if all else fails
      return `Search for "${query}" encountered an error: ${error.message}
      
      Unable to perform web search at this time. Source validation will be limited to cross-referencing with existing knowledge.`;
    }
  }

  async executeStep(step, context, scenarioId) {
    // Validate step object
    if (!step || typeof step !== "object") {
      throw new Error("Invalid step object provided");
    }

    if (!step.id) {
      throw new Error("Step object missing required 'id' property");
    }

    if (!step.model) {
      throw new Error("Step object missing required 'model' property");
    }

    // ENHANCED: Check if this is an enhanced workflow step with capabilities
    if (step.capabilities && Array.isArray(step.capabilities)) {
      return await this.executeEnhancedStep(step, context, scenarioId);
    }

    // Legacy workflow execution path
    const targetModel = this.resolveModel(step.model, step.id, scenarioId);

    if (!targetModel) {
      throw new Error("No available model for this step");
    }

    // Handle special multi-model validation step
    if (targetModel === "all-models") {
      return await this.executeMultiModelValidation(
        step.rawPrompt || step.prompt,
        context
      );
    }

    // NEW: Handle Google search validation step
    if (targetModel === "google-search") {
      return await this.executeGoogleSearchValidation(
        step.rawPrompt || step.prompt,
        context
      );
    }

    // Handle final verification step with validation context
    if (
      step.id === "final-source-verification" &&
      (context.validationResults || context.googleSearchValidation)
    ) {
      // Safely access validation results with fallbacks
      const googleValidation = context.googleSearchValidation || {};
      const validSources = googleValidation.validSources || [];
      const invalidSources = googleValidation.invalidSources || [];
      const questionableSources = googleValidation.questionableSources || [];
      const totalSources = googleValidation.totalSources || 0;
      const invalidPercentage = googleValidation.invalidPercentage || 0;
      const cleanedContent = googleValidation.cleanedContent;

      // Safely get the current content
      const currentContent =
        Array.isArray(context.stepOutputs) && context.stepOutputs.length > 0
          ? context.stepOutputs[context.stepOutputs.length - 1]
          : "";

      // If no sources were validated or too many are invalid, return cleaned content
      if (
        validSources.length === 0 ||
        invalidPercentage > 0.5 ||
        totalSources === 0
      ) {
        const finalCleanedContent =
          cleanedContent || this.removeAllReferences(currentContent);

        return `Final Source Verification Complete:

üìä VERIFICATION SUMMARY:
- Total sources found: ${totalSources}
- Valid sources: ${validSources.length}
- Invalid/Questionable sources: ${
          invalidSources.length + questionableSources.length
        }
- Action taken: All references removed

‚úÖ FINAL CLEANED CONTENT:
${finalCleanedContent}

üîç VERIFICATION NOTES:
Since no sources could be validated or the majority were unreliable, all reference language has been removed. The content now presents facts without citation claims, ensuring accuracy and reliability.`;
      }

      const verificationPrompt = `You are Claude with thinking and web search capabilities. You have received source validation assessments from all 4 AI models (GPT, Claude, Gemini, and Grok)${
        context.googleSearchValidation
          ? " and Google Search validation results"
          : ""
      }. Your task is to:

1. Use web search to independently verify any questionable sources identified
2. Analyze all validation reports with special trust for Grok and Gemini's source assessments
3. ${
        context.googleSearchValidation
          ? "Review Google Search validation results for definitive source verification"
          : "Focus on multi-model validation results"
      }
4. Identify any hallucinated or unreliable sources that need removal
5. Provide a final cleaned version of the content with problematic sources removed
6. List what changes were made and why, with ${
        context.googleSearchValidation ? "search-verified" : "multi-model"
      } reasoning

Validation Reports:
GPT Assessment: {{gptValidation}}
Claude Assessment: {{claudeValidation}}
Gemini Assessment: {{geminiValidation}}
Grok Assessment: {{grokValidation}}${
        context.googleSearchValidation
          ? `
Google Search Validation Results: 
- Total sources checked: ${totalSources}
- Valid sources: ${validSources.length}
- Invalid sources: ${invalidSources.length}
- Questionable sources: ${questionableSources.length}
- Flagged sources for removal: ${[...invalidSources, ...questionableSources]
              .map((s) => `"${s.source}" (${s.status}: ${s.reason})`)
              .join(", ")}
- Invalid percentage: ${Math.round(invalidPercentage * 100)}%`
          : ""
      }

Original Content:
{{originalContent}}

${
  context.googleSearchValidation
    ? "Based on the Google Search validation results, remove or modify all content related to the flagged sources. Pay special attention to sources marked as INVALID or QUESTIONABLE."
    : "Use your search capabilities to verify any disputed sources and provide your final verified content with change summary."
}`;

      const renderedPrompt = this.renderPrompt(verificationPrompt, context);
      console.log(
        `üöÄ Workflow Engine: Final source verification with Claude + ${
          context.googleSearchValidation
            ? "Google search results"
            : "multi-model validation"
        }`
      );

      return await modelHandlers.claude(renderedPrompt, context, true);
    }

    const renderedPrompt = this.renderPrompt(
      step.rawPrompt || step.prompt,
      context
    );

    // Determine if this step should use search
    const useSearch = this.shouldUseSearch(step.id, renderedPrompt);

    console.log(
      `üöÄ Workflow Engine: Executing step "${
        step.id
      }" with ${targetModel.toUpperCase()}${useSearch ? " + search" : ""}`
    );

    return await modelHandlers[targetModel](renderedPrompt, context, useSearch);
  }

  // NEW: Enhanced workflow step execution with capability-based routing
  async executeEnhancedStep(step, context, scenarioId) {
    console.log(
      `üéØ Enhanced Workflow: Processing step "${
        step.id
      }" with capabilities: [${step.capabilities.join(", ")}]`
    );

    // Capability-based model selection
    const targetModel = this.selectOptimalModel(
      step.capabilities,
      step.prioritizeBy
    );

    if (!targetModel) {
      throw new Error(
        `No model available for capabilities: ${step.capabilities.join(", ")}`
      );
    }

    const routingReason = `Selected for capabilities: ${step.capabilities.join(
      "+"
    )} (optimized for ${step.prioritizeBy || "accuracy"})`;
    console.log(
      `üéØ Capability routing: ${step.capabilities.join(
        "+"
      )} ‚Üí ${targetModel.toUpperCase()} (${routingReason})`
    );

    const renderedPrompt = this.renderPrompt(
      step.rawPrompt || step.prompt,
      context
    );

    // Enhanced steps that need search capabilities
    const useSearch =
      this.shouldUseSearch(step.id, renderedPrompt) ||
      step.capabilities.includes("live-web") ||
      step.capabilities.includes("real-time-data") ||
      step.capabilities.includes("fact-checking");

    console.log(
      `üöÄ Enhanced Workflow Engine: Executing step "${
        step.id
      }" with ${targetModel.toUpperCase()}${useSearch ? " + search" : ""}`
    );

    const result = await modelHandlers[targetModel](
      renderedPrompt,
      context,
      useSearch
    );

    // Enhanced validation if requested
    if (step.requiresValidation && step.validationType) {
      console.log(`üîç Running enhanced ${step.validationType} validation`);
      return await this.runEnhancedValidation(
        result,
        step.validationType,
        context
      );
    }

    return result;
  }

  // NEW: Capability-based model selection (simplified version for API server)
  selectOptimalModel(capabilities, prioritizeBy = "accuracy") {
    // Model capability mappings (updated to match enhanced workflow capabilities)
    const modelCapabilities = {
      gpt: [
        "creative-polish",
        "json-output",
        "human-like-voice",
        "creative_polish",
        "json_output",
        "fact_checking",
        "structural-analysis",
      ],
      claude: [
        "long-form-narrative",
        "structural-analysis",
        "logical-reasoning",
        "comprehensive-review",
        "logic-audit",
        "fact-checking",
        "source_verification",
        "logic_audit",
        "long_form_narrative",
      ],
      gemini: [
        "high-context-analysis",
        "document-analysis",
        "comprehensive-review",
        "fact-checking",
        "source-verification",
        "high_volume_research",
        "multimodal_rag",
        "document_analysis",
        "long_context",
      ],
      grok: [
        "live-web",
        "real-time-data",
        "fact-checking",
        "high-volume-research",
        "stem_math_reasoning",
        "real_time_data",
        "live_web",
        "source_validation",
      ],
    };

    // Find models that can handle ALL required capabilities
    const availableModels = Object.keys(modelCapabilities).filter(
      (model) =>
        modelsConfig.enabledDrivers[model] &&
        capabilities.every((cap) => modelCapabilities[model].includes(cap))
    );

    if (availableModels.length === 0) {
      // Fallback: find model with most matching capabilities
      const candidateModels = Object.keys(modelCapabilities)
        .filter((model) => modelsConfig.enabledDrivers[model])
        .map((model) => ({
          model,
          matchScore: capabilities.filter((cap) =>
            modelCapabilities[model].includes(cap)
          ).length,
        }))
        .sort((a, b) => b.matchScore - a.matchScore);

      if (candidateModels.length > 0) {
        console.log(
          `‚ö†Ô∏è No perfect match for [${capabilities.join(
            ", "
          )}], using best available: ${candidateModels[0].model.toUpperCase()}`
        );
        return candidateModels[0].model;
      }
      return null;
    }

    // Priority-based selection among capable models
    if (prioritizeBy === "context" && availableModels.includes("gemini")) {
      return "gemini"; // 1M context window
    }
    if (prioritizeBy === "accuracy" && availableModels.includes("claude")) {
      return "claude"; // Highest accuracy score
    }
    if (prioritizeBy === "cost" && availableModels.includes("gemini")) {
      return "gemini"; // Lowest cost tier
    }
    if (prioritizeBy === "latency" && availableModels.includes("gpt")) {
      return "gpt"; // Fastest response
    }

    // Default to first available model
    return availableModels[0];
  }

  // NEW: Enhanced validation using cross-model checking
  async runEnhancedValidation(content, validationType, context) {
    console.log(`üîç Running enhanced ${validationType} validation`);

    const validationPrompts = {
      fact_check: `You are a fact-checking expert. Analyze the following content for factual accuracy and logical consistency. Identify any questionable claims, unsupported statements, or potential misinformation. Rate your confidence in the content's accuracy (1-10):\n\n${content}`,
      source_verify: `You are a source verification specialist. Examine the following content for source reliability, citation quality, and reference authenticity. Identify any questionable sources or unsupported claims. Rate source reliability (1-10):\n\n${content}`,
      logic_audit: `You are a logic and reasoning expert. Analyze the following content for logical consistency, argument structure, and reasoning quality. Identify any logical fallacies, inconsistencies, or weak arguments. Rate logical coherence (1-10):\n\n${content}`,
    };

    // Use two different models for cross-validation
    const validationModels =
      validationType === "fact_check"
        ? ["gpt", "claude"]
        : validationType === "source_verify"
        ? ["grok", "gemini"]
        : ["claude", "gpt"]; // logic_audit

    const prompt = validationPrompts[validationType];

    try {
      const validationPromises = validationModels
        .filter((model) => modelsConfig.enabledDrivers[model])
        .slice(0, 2) // Limit to 2 models for performance
        .map(async (model) => {
          try {
            return await modelHandlers[model](prompt, context, true); // Use search for validation
          } catch (error) {
            return `Validation failed: ${error.message}`;
          }
        });

      const validationResults = await Promise.all(validationPromises);

      // Return original content with validation summary
      return `${content}\n\n---\nüîç Enhanced ${validationType} validation completed:\n${validationResults
        .map(
          (result, i) =>
            `${validationModels[i].toUpperCase()}: ${result.substring(
              0,
              200
            )}...`
        )
        .join("\n\n")}`;
    } catch (error) {
      console.error(`‚ùå Enhanced validation failed:`, error.message);
      return content; // Return original content if validation fails
    }
  }

  toggleDriver(driverName, enabled) {
    modelsConfig.enabledDrivers[driverName] = enabled;
    console.log(`üîß Driver ${driverName} ${enabled ? "enabled" : "disabled"}`);
  }

  getDriverStatus() {
    return { ...modelsConfig.enabledDrivers };
  }

  // NEW: Helper to remove all reference patterns from content
  removeAllReferences(content) {
    if (!content || typeof content !== "string") {
      return content;
    }

    let cleanedContent = content;

    // Remove [Source: ...] but keep any preceding substantive content
    cleanedContent = cleanedContent.replace(/\s*\[Source:\s*([^\]]+)\]/gi, "");

    // Remove (Source: ...) but keep any preceding substantive content
    cleanedContent = cleanedContent.replace(/\s*\(Source:\s*([^\)]+)\)/gi, "");

    // Remove standalone URLs but preserve content around them
    cleanedContent = cleanedContent.replace(
      /\s*https?:\/\/[^\s\)\]\}\<\>\n]+\s*/g,
      " "
    );

    // Remove citation patterns like "(Author, Year)" or "[1]" or "[Author 2023]"
    cleanedContent = cleanedContent.replace(
      /\s*\([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*,?\s*\d{4}\)\s*/g,
      " "
    );
    cleanedContent = cleanedContent.replace(
      /\s*\[[^\]]*\d{4}[^\]]*\]\s*/g,
      " "
    );
    cleanedContent = cleanedContent.replace(/\s*\[\d+\]\s*/g, " ");

    // PRESERVE substantive content - only remove introductory citation phrases, not the facts
    // Instead of removing entire sentences, just remove the attribution parts
    cleanedContent = cleanedContent.replace(
      /According to\s+[^,.\n]+[,.]?\s*/gi,
      ""
    );
    cleanedContent = cleanedContent.replace(
      /As reported by\s+[^,.\n]+[,.]?\s*/gi,
      ""
    );
    cleanedContent = cleanedContent.replace(
      /The\s+(?:study|research|report|paper|article)\s+by\s+[^,.\n]+[,.]?\s*/gi,
      "The research "
    );

    // Remove author attributions but keep the actual findings/claims
    cleanedContent = cleanedContent.replace(
      /([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+(?:states|reports|claims|found|discovered|published)\s+(?:that\s+)?/gi,
      "Research shows "
    );

    // Replace research introduction phrases with neutral versions
    cleanedContent = cleanedContent.replace(
      /(?:research shows|studies indicate|data suggests|evidence suggests|findings reveal|analysis shows)\s+that\s+/gi,
      ""
    );
    cleanedContent = cleanedContent.replace(
      /(?:researchers?|scientists?|experts?|analysts?)\s+(?:found|discovered|determined|concluded|reported|stated)\s+(?:that\s+)?/gi,
      ""
    );

    // Clean up punctuation and spacing issues
    cleanedContent = cleanedContent.replace(/\s*,\s*,/g, ","); // Remove double commas
    cleanedContent = cleanedContent.replace(/\s*\.\s*\./g, "."); // Remove double periods
    cleanedContent = cleanedContent.replace(/\s+/g, " "); // Normalize whitespace
    cleanedContent = cleanedContent.replace(/\s*,\s*\./g, "."); // Remove comma before period
    cleanedContent = cleanedContent.replace(/\.\s*,/g, "."); // Remove comma after period
    cleanedContent = cleanedContent.replace(/\s*\.\s*/g, ". "); // Normalize period spacing
    cleanedContent = cleanedContent.replace(/\s*,\s*/g, ", "); // Normalize comma spacing

    // Remove leftover fragments but preserve meaningful sentences
    cleanedContent = cleanedContent.replace(
      /\s*,\s*the\s+data\s+shows\s*/gi,
      " "
    );
    cleanedContent = cleanedContent.replace(
      /\s*,\s*the\s+(?:study|research)\s+(?:shows|indicates)\s*/gi,
      " "
    );

    // Fix sentence beginnings that might have been broken
    cleanedContent = cleanedContent.replace(/\.\s*The\s*\./g, ".");
    cleanedContent = cleanedContent.replace(/\.\s*Research\s+\./g, ".");

    // Ensure sentences start with capital letters after cleanup
    cleanedContent = cleanedContent.replace(
      /\.\s+([a-z])/g,
      (match, letter) => ". " + letter.toUpperCase()
    );

    // Final cleanup
    cleanedContent = cleanedContent.replace(/\s+/g, " ").trim();
    cleanedContent = cleanedContent.replace(/\s*\.\s*$/g, "."); // Ensure proper ending

    return cleanedContent;
  }
}

const workflowEngine = new WorkflowEngine();

// Auth Routes
app.get("/auth/google", passport.authenticate("google", { scope: ["profile", "email"] }));

app.get(
  "/auth/google/callback",
  passport.authenticate("google", { failureRedirect: "/login" }),
  (req, res) => {
    console.log('üéâ Google OAuth callback successful!');
    console.log('üë§ User data:', req.user);
    console.log('üîí Session ID:', req.sessionID);
    console.log('‚úÖ Is authenticated:', req.isAuthenticated());
    
    // Successful authentication, redirect to home with auth trigger
    res.redirect("/?auth=success");
  }
);

app.get("/auth/logout", (req, res) => {
  req.logout((err) => {
    if (err) {
      return res.status(500).json({ error: "Logout failed" });
    }
    res.json({ message: "Logged out successfully" });
  });
});

app.get("/auth/user", (req, res) => {
  console.log('üîç Auth check request:', {
    isAuthenticated: req.isAuthenticated(),
    user: req.user,
    sessionID: req.sessionID,
    cookies: req.headers.cookie,
    session: req.session
  });
  
  if (req.isAuthenticated()) {
    console.log('‚úÖ User is authenticated:', req.user);
    res.json({ user: req.user });
  } else {
    console.log('‚ùå User not authenticated');
    res.json({ user: null });
  }
});

// Debug endpoint to check session
app.get("/auth/debug", (req, res) => {
  res.json({
    sessionID: req.sessionID,
    isAuthenticated: req.isAuthenticated(),
    user: req.user,
    session: req.session,
    cookies: req.headers.cookie
  });
});

// API Routes
app.get("/api/test", (req, res) => {
  res.status(200).send("Test route is working!");
});

app.post("/api/generate", requireAuth, async (req, res) => {
  const { model, prompt, context, useSearch } = req.body;

  if (!model || !prompt) {
    return res.status(400).json({ error: "Model and prompt are required" });
  }

  const handler = modelHandlers[model];
  if (!handler) {
    return res.status(400).json({ error: "Unsupported model" });
  }

  try {
    const result = await handler(prompt, context, useSearch);
    res.json({ text: result });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Legacy streaming API deprecation
app.post("/api/stream", async (req, res) => {
  return res.status(410).json({
    success: false,
    error: "Streaming API deprecated. Use /api/run for regular responses.",
    migration:
      "Update client to use regular HTTP requests with /api/run endpoint",
  });
});

// Driver management
app.post("/api/drivers/toggle", (req, res) => {
  try {
    const { driver, enabled } = req.body;
    workflowEngine.toggleDriver(driver, enabled);

    res.json({
      success: true,
      drivers: workflowEngine.getDriverStatus(),
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message,
    });
  }
});

app.get("/api/drivers", (req, res) => {
  res.json({
    success: true,
    drivers: workflowEngine.getDriverStatus(),
    capabilities: {
      gpt: {
        strengths: [
          "logic_audit",
          "creative_polish",
          "fact_checking",
          "json_output",
        ],
        contextLimit: 128000,
        costTier: "medium",
      },
      claude: {
        strengths: [
          "long_form_narrative",
          "structural_analysis",
          "logical_reasoning",
        ],
        contextLimit: 200000,
        costTier: "medium",
      },
      gemini: {
        strengths: [
          "high_volume_research",
          "multimodal_rag",
          "document_analysis",
        ],
        contextLimit: 1000000,
        costTier: "low",
      },
      grok: {
        strengths: [
          "stem_math_reasoning",
          "real_time_data",
          "social_web_search",
        ],
        contextLimit: 128000,
        costTier: "high",
      },
    },
  });
});

// Health check
app.get("/api/health", (req, res) => {
  res.json({
    status: "ok",
    timestamp: new Date().toISOString(),
    version: "4.0.0-standard",
    models: {
      gpt: !!process.env.OPENAI_API_KEY,
      claude: !!process.env.ANTHROPIC_API_KEY,
      gemini: !!process.env.GEMINI_API_KEY,
      grok: !!process.env.GROK_API_KEY,
    },
    drivers: workflowEngine.getDriverStatus(),
  });
});

// Any requests that don't match the API route should be handled by the frontend
app.use((req, res) => {
  res.sendFile(path.join(__dirname, "dist", "index.html"));
});

app.listen(port, () => {
  console.log(
    `üöÄ AI Ping-Pong Studio v4 API Server running on http://localhost:${port}`
  );
  console.log(
    `Main generation endpoint: http://localhost:${port}/api/generate`
  );
  
  console.log(`\nüîê Google OAuth Status:`);
  console.log(
    `   Google Client ID: ${
      process.env.GOOGLE_CLIENT_ID ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   Google Client Secret: ${
      process.env.GOOGLE_CLIENT_SECRET ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   Session Secret: ${
      process.env.SESSION_SECRET ? "‚úÖ Configured" : "‚ùå Using default"
    }`
  );
  
  console.log(`\nüîë API Key Status:`);
  console.log(
    `   OpenAI (GPT): ${
      process.env.OPENAI_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   Anthropic (Claude): ${
      process.env.ANTHROPIC_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   Google (Gemini): ${
      process.env.GEMINI_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );
  console.log(
    `   xAI (Grok): ${
      process.env.GROK_API_KEY ? "‚úÖ Configured" : "‚ùå Missing"
    }`
  );

  console.log(`\nüîß Driver Status:`);
  const drivers = workflowEngine.getDriverStatus();
  Object.entries(drivers).forEach(([name, enabled]) => {
    console.log(
      `   ${name.toUpperCase()}: ${enabled ? "‚úÖ Enabled" : "‚ùå Missing"}`
    );
  });

  if (
    !process.env.OPENAI_API_KEY &&
    !process.env.ANTHROPIC_API_KEY &&
    !process.env.GEMINI_API_KEY
  ) {
    console.log(`\n‚ùó WARNING: No API keys found!`);
    console.log(`   Add API keys to your .env file:`);
    console.log(`   OPENAI_API_KEY=your_openai_key`);
    console.log(`   ANTHROPIC_API_KEY=your_anthropic_key`);
    console.log(`   GEMINI_API_KEY=your_gemini_key`);
    console.log(`   GROK_API_KEY=your_grok_key`);
  }
  console.log(``);
});
